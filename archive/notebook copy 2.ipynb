{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "\n",
    "openai_client = OpenAI(api_key = open_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf_extraction\u001b[39;00m\n\u001b[0;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(modules\u001b[38;5;241m.\u001b[39mpdf_extraction)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf_extraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_text_from_pages, select_pdf_file\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import modules.pdf_extraction\n",
    "importlib.reload(modules.pdf_extraction)\n",
    "from modules.pdf_extraction import extract_text_from_pages, select_pdf_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = select_pdf_file()\n",
    "# input page no\n",
    "page_no = 0\n",
    "\n",
    "extracted_text = extract_text_from_pages(pdf_path, pages=page_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Number of Tables on the Page: 1\\n\\n2. Table Headers: Organic Items Price/kg Quantity(kg) Subtotal\\n\\n3. Rules for Parsing Tables and Headers:\\n   - Look for sequences of words followed by consistent data types (e.g., words followed by numbers), indicating tabular data.\\n   - Identify headers as lines with multiple columns where text typically appears capitalized or bold.\\n   - Table headers often contain key business terms or product descriptions.\\n   - Look for repeated patterns, like price followed by a unit and quantity, as an indicator of rows in a table.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymupdf \n",
    "## 111\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "import modules.pdf_extraction\n",
    "importlib.reload(modules.llm)\n",
    "importlib.reload(modules.pdf_extraction)\n",
    "\n",
    "from modules.llm import pattern_description_llm, table_extraction\n",
    "from modules.pdf_extraction import get_page_pixel_data\n",
    "\n",
    "\n",
    "base64_image = get_page_pixel_data(pdf_path=pdf_path, page_no=page_no, \n",
    "                    dpi = 500, image_type = 'png')\n",
    "\n",
    "# perhaps let it run twice to make super sure. if the numbers do not match run again and pick the max. If it still does not work then just pick one\n",
    "pattern_desc_from_image = pattern_description_llm(text_input = extracted_text, model='gpt-4o',  base64_image = base64_image, open_api_key=open_api_key)\n",
    "\n",
    "pattern_desc_from_image\n",
    "\n",
    "# Function to process each row in parallel\n",
    "# open ai does not seem to have structed output for this image input version.\n",
    "# Ill pass it as text to the next llm# 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the respective variable outputs\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "text = pattern_desc_from_image\n",
    "# 1) Extract the Number of Tables\n",
    "match_num_tables = re.search(r'Number of Tables on the Page:\\s*(\\d+)', text)\n",
    "if match_num_tables:\n",
    "    num_tables = int(match_num_tables.group(1))\n",
    "else:\n",
    "    num_tables = None  # or handle error\n",
    "\n",
    "# 2) Extract the Table Headers\n",
    "#    We'll grab everything after \"Table Headers:\" until the line \"3. Rules\" begins\n",
    "match_headers = re.search(r'Table Headers:\\s*(.*?)\\s*\\n\\s*3\\.', text, re.DOTALL)\n",
    "if match_headers:\n",
    "    headers_text = match_headers.group(1)\n",
    "    # Split on '||' to get individual headers\n",
    "    table_headers = [h.strip() for h in headers_text.split('||')]\n",
    "else:\n",
    "    table_headers = []\n",
    "\n",
    "# 3) Extract the Rules for Parsing Tables and Headers\n",
    "#    We'll capture everything after \"3. Rules for Parsing Tables and Headers:\" until the end\n",
    "match_rules = re.search(r'3\\. Rules for Parsing Tables and Headers:\\s*(.*)', text, re.DOTALL)\n",
    "if match_rules:\n",
    "    parsing_rules = match_rules.group(1).strip()\n",
    "else:\n",
    "    parsing_rules = \"\"\n",
    "\n",
    "# # Print or use these variables as needed\n",
    "# print(\"Number of Tables:\", num_tables)\n",
    "# print(\"Table Headers:\", table_headers)\n",
    "# print(\"Rules for Parsing Tables and Headers:\\n\", parsing_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Organic Items Price/kg Quantity(kg) Subtotal']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'``````````````````````\\nindex: [0], table_header or descriptor: [Organic Items Price/kg Quantity(kg) Subtotal], column_names: [organic_items, price_kg, quantity_kg, subtotal, farm_name]\\n``````````````````````'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerical columns as an additional feature\n",
    "\n",
    "user_text='Extract all the data from the table also create a column with which contains the name of the farm for each row'\n",
    "\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import vision_column_llm_parser\n",
    "# use user input to determine table of interst\n",
    "# variable_col_data = vision_column_llm_parser(user_text='Extract all data from the table i also want a column which tells me when the bend radius is above 1000',\n",
    "#                                     table_to_target= table_headers[0],\n",
    "#                                     base64_image=base64_image,\n",
    "#                                     open_api_key=open_api_key)\n",
    "\n",
    "variable_col_data = vision_column_llm_parser(user_text=user_text,\n",
    "                                   text_input= extracted_text,\n",
    "                                    table_to_target= headers_text,\n",
    "                                    base64_image=base64_image,\n",
    "                                    open_api_key=open_api_key)\n",
    "variable_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # Your text\n",
    "# text =variable_col_data\n",
    "\n",
    "# pattern = r'index:\\s*\\[(\\d+)\\].*?column_names:\\s*\\[(.*?)\\]'\n",
    "# matches = re.findall(pattern, text)\n",
    "\n",
    "# results = []\n",
    "# for index_str, columns_str in matches:\n",
    "#     index_value = int(index_str)\n",
    "    \n",
    "#     # 1) Strip any extra whitespace\n",
    "#     # 2) Then remove leading/trailing brackets (e.g. \"[...\" or \"...]\")\n",
    "#     columns_str = columns_str.strip().strip(\"[]\")\n",
    "    \n",
    "#     # Now split on commas to get a proper list\n",
    "#     columns_list = [col.strip() for col in columns_str.split(',')]\n",
    "    \n",
    "#     # Fetch the correct table_header using index\n",
    "#     header = table_headers[index_value]\n",
    "    \n",
    "#     results.append({\n",
    "#         \"index\": index_value,\n",
    "#         \"table_header\": header,\n",
    "#         \"column_names\": columns_list\n",
    "#     })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(results[0]['column_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = variable_col_data\n",
    "pattern = r'index:\\s*\\[(\\d+)\\].*?column_names:\\s*\\[(.*?)\\]'\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "results = []\n",
    "for index_str, columns_str in matches:\n",
    "    index_value = int(index_str)\n",
    "    columns_list = [col.strip() for col in columns_str.split(',')]\n",
    "    \n",
    "    # Use the table_headers list to fetch the header based on index\n",
    "    header = table_headers[index_value]\n",
    "    \n",
    "    results.append({\n",
    "        \"index\": index_value,\n",
    "        \"table_header\": header,\n",
    "        \"column_names\": columns_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import importlib\n",
    "# import modules.llm\n",
    "# importlib.reload(modules.llm)\n",
    "# from modules.llm import variable_extractor_llm\n",
    "\n",
    "# var_list =  variable_extractor_llm(user_text= 'return every column in the table',\n",
    "#                                     text_data=extracted_text, \n",
    "#                                     target_table= table_headers[2],\n",
    "#                                     pattern =parsing_rules,\n",
    "#                                     openai_client=openai_client, \n",
    "#                                     model='gpt-4o') # gpt-4o\n",
    "# var_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Organic Items Price/kg Quantity(kg) Subtotal'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_index = 0\n",
    "table_headers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['farm_name', 'organic_items', 'price_kg', 'quantity_kg', 'subtotal']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fields = sorted(set(results[table_index]['column_names'])) # in case of dups\n",
    "input_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import base64\n",
    "\n",
    "# def load_image(inputs: dict) -> dict:\n",
    "#     \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "#     image_path = inputs[\"image_path\"]\n",
    "  \n",
    "#     def encode_image(image_path):\n",
    "#         with open(image_path, \"rb\") as image_file:\n",
    "#             return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "#     image_base64 = encode_image(image_path)\n",
    "#     return {\"image\": image_base64}\n",
    "\n",
    "\n",
    "# from langchain.chains import TransformChain\n",
    "\n",
    "# load_image_chain = TransformChain(\n",
    "#     input_variables=[\"image_path\"],\n",
    "#     output_variables=[\"image\"],\n",
    "#     transform=load_image\n",
    "# )\n",
    "\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# class ImageInformation(BaseModel):\n",
    "#  \"\"\"Information about an image.\"\"\"\n",
    "#  column_0303: list[str] = Field(description=\"Column name called 0303\")\n",
    "#  bend_radius_mm: list[str] = Field(description=\"Column   name called bend_radius_mm\")\n",
    "#  burst_pressure_bar: list[str] = Field(description=\"Column name called burst_pressure_bar\")\n",
    "#  id: list[str] = Field(description=\"Column name called id\")\n",
    "#  max_pressure_bar: list[str] = Field(description=\"Column name called max_pressure_bar\")\n",
    "#  od_mm: list[str] = Field(description=\"Column name called od_mm\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from langchain.chains import TransformChain\n",
    "# from langchain_core.messages import HumanMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain import globals\n",
    "# from langchain_core.runnables import chain\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "# parser = JsonOutputParser(pydantic_object=ImageInformation)\n",
    "\n",
    "# # Set verbose\n",
    "# globals.set_debug(True)\n",
    "\n",
    "# @chain\n",
    "# def image_model(inputs: dict) -> str | list[str] | dict:\n",
    "#  \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "#  model = ChatOpenAI(temperature=0.8, model=\"gpt-4o\", max_tokens=3000)\n",
    "#  msg = model.invoke(\n",
    "#              [HumanMessage(\n",
    "#              content=[\n",
    "#              {\"type\": \"text\", \"text\": inputs[\"prompt\"]},\n",
    "#              {\"type\": \"text\", \"text\": parser.get_format_instructions()},\n",
    "#              {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{inputs['image']}\"}},\n",
    "#              ])]\n",
    "#              )\n",
    "#  return msg.content\n",
    "\n",
    "\n",
    "\n",
    "# # vision_prompt =   f\"\"\"  \n",
    "\n",
    "# # You are a skilled data extraction and parsing specialist with expertise in analysing PDF text and image documents and extracting structured information from tables.\n",
    "\n",
    "# #           You will be provided with:\n",
    "\n",
    "# #           * A users request. \n",
    "# #           * Table headers or descriptors\n",
    "# #           * An image of the PDF page for reference.\n",
    "# #           * All text data on the PDF page. \n",
    "\n",
    "       \n",
    "# #         Your job is to read a user's request, the image of the page and the tex document. \n",
    "# #         You are to identify and extract the column names of each table specified in line with the user's request. \n",
    "# #         If there are multiple tables they will be sepreated with \" || \" .\n",
    "# #         Column names refer to the labels assigned to each column with populated values. Columns names may be text, numerical, alphanumerial and could sometimes contian special characters.\n",
    "# #         The user request may sometimes imply the extraction of select column names or generating new ones. e.g header column name\n",
    "# #         Return these column names in a list with the corresponding table header and description and its index in the list. \n",
    "# #         For a giving column name ensure the spaces within it are replaced with an under score for example (if the variable is \"pack quantity\" ensure you return \"pack_qunatity\") and ensure it is lower cased\n",
    "        \n",
    "# #         Example\n",
    "        \n",
    "# #         ``````````````````````\n",
    "# #         User's request: I want to extract all data in the columns as well as the header which is ontop of the table\n",
    "# #         ``````````````````````\n",
    "\n",
    "# #         ``````````````````````\n",
    "# #         Table to extract the column names from: [Metric Male 24 Cone Seat,S Series, DIN 3865 || Standpipe,S Series]\n",
    "# #         ``````````````````````\n",
    "        \n",
    "# #         ``````````````````````\n",
    "# #         Text document: '\\n\\n--- Page 1 ---\\n\\n21\\n1.01  Hydraulic Hose & Inserts\\nHydraulics\\n1\\n Metric Heavy Series\\n Hexavalent chromium free plating\\nMetric Male 24¡ Cone Seat, \\nS Series, DIN 3865\\n0309\\nThread\\nTo Suit\\nHose ID\\nSize\\nHMMS03-M16CF\\nM16 x 1.5\\n3/16”\\n8S\\nHMMS04-M14CF\\nM14 x 1.5\\n1/4”\\n6S\\nHMMS04-M16CF\\nM16 x 1.5\\n1/4”\\n8S\\nHMMS04-M18CF\\nM18 x 1.5\\n1/4”\\n10S\\nHMMS05-M18CF\\nM18 x 1.5\\n5/16”\\n10S\\nHMMS05-M20CF\\nM20 x 1.5\\n5/16”\\n12S\\nHMMS06-M18CF\\nM18 x 1.5\\n3/8”\\n10S\\nHMMS06-M20CF\\nM20 x 1.5\\n3/8”\\n12S\\nHMMS06-M22CF\\nM22 x 1.5\\n3/8”\\n14S\\nHMMS06-M24CF\\nM24 x 1.5\\n3/8”\\n16S\\nHMMS08-M24CF\\nM24 x 1.5\\n1/2”\\n16S\\nHMMS10-M30CF\\nM30 x 2\\n5/8”\\n20S\\nHMMS12-M30CF\\nM30 x 2\\n3/4”\\n20S\\nHMMS12-M36CF\\nM36 x 2\\n3/4”\\n25S\\nHMMS16-M36CF\\nM36 x 1.5\\n1”\\n25S\\nHMMS16-M42CF\\nM42 x 2\\n1”\\n30S\\nHMMS20-M42CF\\nM42 x 2\\n1.1/4”\\n30S\\nHMMS20-M52CF\\nM52 x 2\\n1.1/4”\\n38S\\nHMMS24-M52CF\\nM52 x 2\\n1.1/2”\\n38S\\nMetric Female 24¡ Cone Seat, \\nS Series, DIN 3865\\n0309\\nThread\\nTo Suit\\nHose ID\\nSize\\nHMFS03-M16CF\\nM16 x 1.5\\n3/16”\\n8S\\nHMFS04-M14CF\\nM14 x 1.5\\n1/4”\\n6S\\nHMFS04-M16CF\\nM16 x 1.5\\n1/4”\\n8S\\nHMFS04-M18CF\\nM18 x 1.5\\n1/4”\\n10S\\nHMFS05-M18CF\\nM18 x 1.5\\n5/16”\\n10S\\nHMFS05-M20CF\\nM20 x 1.5\\n5/16”\\n12S\\nHMFS06-M16CF\\nM16 x 1.5\\n3/8”\\n8S\\nHMFS06-M18CF\\nM18 x 1.5\\n3/8”\\n10S\\nHMFS06-M20CF\\nM20 x 1.5\\n3/8”\\n12S\\nHMFS06-M22CF\\nM22 x 1.5\\n3/8”\\n14S\\nHMFS08-M22CF\\nM22 x 1.5\\n1/2”\\n14S\\nHMFS08-M24CF\\nM24 x 1.5\\n1/2”\\n16S\\nHMFS08-M30CF\\nM30 x 2\\n1/2”\\n20S\\nHMFS10-M24CF\\nM24 x 1.5\\n5/8”\\n16S\\nHMFS10-M30CF\\nM30 x 2\\n5/8”\\n20S\\nHMFS12-M30CF\\nM30 x 2\\n3/4”\\n20S\\nHMFS12-M36CF\\nM36 x 2\\n3/4”\\n25S\\nHMFS16-M36CF\\nM36 x 2\\n1”\\n25S\\nHMFS16-M42CF\\nM42 x 2\\n1”\\n30S\\nHMFS20-M52CF\\nM52 x 2\\n1.1/4”\\n38S\\nHMFS24-M52CF\\nM52 x 2\\n1.1/2”\\n38S\\n90¡ Metric Female 24¡ Cone Seat, \\nS Series, DIN 3865\\n0309\\nThread\\nTo Suit\\nHose ID\\nSize\\nHMFS0390-M16CF\\nM16 x 1.5\\n3/16”\\n8S\\nHMFS0490-M14CF\\nM14 x 1.5\\n1/4”\\n6S\\nHMFS0490-M16CF\\nM16 x 1.5\\n1/4”\\n8S\\nHMFS0490-M18CF\\nM18 x 1.5\\n1/4”\\n10S\\nHMFS0490-M20CF\\nM20 x 1.5\\n1/4”\\n12S\\nHMFS0590-M18CF\\nM18 x 1.5\\n5/16”\\n10S\\nHMFS0590-M20CF\\nM20 x 1.5\\n5/16”\\n12S\\nHMFS0690-M18CF\\nM18 x 1.5\\n3/8”\\n10S\\nHMFS0690-M20CF\\nM20 x 1.5\\n3/8”\\n12S\\nHMFS0690-M22CF\\nM22 x 1.5\\n3/8”\\n14S\\nHMFS0890-M24CF\\nM24 x 1.5\\n1/2”\\n16S\\nHMFS1090-M24CF\\nM24 x 1.5\\n5/8”\\n16S\\nHMFS1090-M30CF\\nM30 x 2\\n5/8”\\n20S\\nHMFS1290-M30CF\\nM30 x 2\\n3/4”\\n20S\\nHMFS1290-M36CF\\nM36 x 2\\n3/4”\\n25S\\nHMFS1690-M36CF\\nM36 x 2\\n1”\\n25S\\nHMFS1690-M42CF\\nM42 x 2\\n1”\\n30S\\nHMFS2090-M52CF\\nM52 x 2\\n1.1/4”\\n38S\\nHMFS2490-M52CF\\nM52 x 2\\n1.1/2”\\n38S\\nStandpipe, \\nS Series\\n0309\\nOD mm\\nTo Suit Hose ID\\nHSSP04-10CF\\n10\\n1/4”\\nHSSP06-14CF\\n14\\n3/8”\\nHSSP08-16CF\\n16\\n1/2”\\nHSSP10-20CF\\n20\\n5/8”\\nHSSP12-20CF\\n20\\n3/4”\\nHSSP12-25CF\\n25\\n3/4”\\nHSSP16-25CF\\n25\\n1”\\nHSSP16-30CF\\n30\\n1”\\nHSSP20-38CF\\n38\\n1.1/4”\\n45¡ Metric Female 24¡ Cone Seat, \\nS Series, DIN 3865\\n0309\\nThread\\nTo Suit\\nHose ID\\nSize\\nHMFS03-45-M16CF\\nM16 x 1.5\\n3/16”\\n8S\\nHMFS04-45-M14CF\\nM14 x 1.5\\n1/4”\\n6S\\nHMFS04-45-M16CF\\nM16 x 1.5\\n1/4”\\n8S\\nHMFS04-45-M18CF\\nM18 x 1.5\\n1/4”\\n10S\\nHMFS05-45-M18CF\\nM18 x 1.5\\n5/16”\\n10S\\nHMFS05-45-M20CF\\nM20 x 1.5\\n5/16”\\n12S\\nHMFS06-45-M20CF\\nM20 x 1.5\\n3/8”\\n12S\\nHMFS06-45-M22CF\\nM22 x 1.5\\n3/8”\\n14S\\nHMFS08-45-M24CF\\nM24 x 1.5\\n1/2”\\n16S\\nHMFS10-45-M30CF\\nM30 x 2\\n5/8”\\n20S\\nHMFS12-45-M30CF\\nM30 x 2\\n3/4”\\n20S\\nHMFS12-45-M36CF\\nM36 x 2\\n3/4”\\n25S\\nHMFS16-45-M36CF\\nM36 x 2\\n1”\\n25S\\nHMFS16-45-M42CF\\nM42 x 2\\n1”\\n30S\\nHMFS20-45-M52CF\\nM52 x 2\\n1.1/4”\\n38S\\nHMFS24-45-M52CF\\nM52 x 2\\n1.1/2”\\n38S\\n90¡ Standpipe, \\nS Series\\n0309\\nOD mm\\nTo Suit Hose ID\\nHSSP04-90-08CF\\n8\\n1/4”\\nHSSP04-90-10CF\\n10\\n1/4”\\nHSSP06-90-14CF\\n14\\n3/8”\\nHSSP08-90-16CF\\n16\\n1/2”\\nHSSP10-90-20CF\\n20\\n5/8”\\nHSSP12-90-20CF\\n20\\n3/4”\\nHSSP12-90-25CF\\n25\\n3/4”\\nHSSP16-90-25CF\\n25\\n1”\\nHSSP16-90-30CF\\n30\\n1”\\n45¡ Standpipe, S Series\\n0309\\nOD mm\\nTo Suit Hose ID\\nHSSP04-45-08CF\\n8\\n1/4”\\nHSSP04-45-10CF\\n10\\n1/4”\\nHSSP04-45-12CF\\n12\\n1/4”\\nHSSP05-45-12CF\\n12\\n5/16”\\nHSSP06-45-14CF\\n14\\n3/8”\\nHSSP08-45-14CF\\n14\\n1/2”\\nHSSP08-45-16CF\\n16\\n1/2”\\nHSSP10-45-16CF\\n16\\n5/8”\\nHSSP10-45-20CF\\n20\\n5/8”\\nHSSP12-45-20CF\\n20\\n3/4”\\nHSSP12-45-25CF\\n25\\n3/4”\\nHSSP16-45-25CF\\n25\\n1”\\nHSSP16-45-30CF\\n30\\n1”\\nHSSP16-45-38CF\\n38\\n1”\\nHSSP20-45-30CF\\n30\\n1.1/4”\\nHSSP20-45-38CF\\n38\\n1.1/4”\\nHYDRAULIC HOSE CONNECTORS'\n",
    "# #         ``````````````````````\n",
    "      \n",
    "# #         Output:\n",
    "# #         ``````````````````````                \n",
    "# #         index: [0], table_header or descriptor: [Metric Male 24 Cone Seat,S Series, DIN 386], column_names: [0309, thread, to_suit_house_id, size, header]\n",
    "# #         index: [1], table_header or descriptor: [Standpipe,S Series], column_names: [0309, od_mm, to_suit_house_id]    \n",
    "# #         ``````````````````````  \n",
    "                  \n",
    "# #         NOTE: Some columns have sub columns under them. Simply append the sub columns to the main column and return them as a unit. \n",
    "        \n",
    "# #         Now provide output in line with the example format for the following: \n",
    "           \n",
    "# #           ``````````````````````````\n",
    "# #           User's request: {user_text}\n",
    "# #           ``````````````````````````\n",
    "\n",
    "# #           ``````````````````````````\n",
    "# #           Table to extract data from: {table_headers[0]}\n",
    "# #           ``````````````````````````\n",
    "\n",
    "# #           ``````````````````````````\n",
    "# #           Text document: {extracted_text}\n",
    "# #           ``````````````````````````\n",
    "# #         \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # def get_image_informations(image_path: str) -> dict:\n",
    "# #    vision_chain = load_image_chain | image_model | parser\n",
    "# #    return vision_chain.invoke({'image_path': f'{image_path}', \n",
    "# #                                'prompt': vision_prompt})\n",
    "\n",
    "# # result = get_image_informations('C:/Users/derri/Desktop/pic of 0012.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'``````````````````````````\\n\\n[farm_name: Melbourne Farm |-| Melbourne Farm |-| Melbourne Farm |-| Melbourne Farm |-| Melbourne Farm],\\n\\n[organic_items: Apple |-| Orange |-| Watermelon |-| Mango |-| Peach],\\n\\n[price_kg: $5.00 |-| $1.99 |-| $1.69 |-| $9.56 |-| $2.99],\\n\\n[quantity_kg: 1 |-| 2 |-| 3 |-| 2 |-| 1],\\n\\n[subtotal: $5.00 |-| $3.98 |-| $5.07 |-| $19.12 |-| $2.99]\\n\\n``````````````````````````'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import vision_llm_parser\n",
    "# use user input to determine table of interst\n",
    "variable_col_data = vision_llm_parser(user_text=user_text,\n",
    "                                   text_input= extracted_text,\n",
    "                                   columns=input_fields,\n",
    "                                    table_to_target= table_headers[0],\n",
    "                                    base64_image=base64_image,\n",
    "                                    open_api_key=open_api_key)\n",
    "variable_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farm_name</th>\n",
       "      <th>organic_items</th>\n",
       "      <th>price_kg</th>\n",
       "      <th>quantity_kg</th>\n",
       "      <th>subtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melbourne Farm</td>\n",
       "      <td>Apple</td>\n",
       "      <td>$5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>$5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melbourne Farm</td>\n",
       "      <td>Orange</td>\n",
       "      <td>$1.99</td>\n",
       "      <td>2</td>\n",
       "      <td>$3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melbourne Farm</td>\n",
       "      <td>Watermelon</td>\n",
       "      <td>$1.69</td>\n",
       "      <td>3</td>\n",
       "      <td>$5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melbourne Farm</td>\n",
       "      <td>Mango</td>\n",
       "      <td>$9.56</td>\n",
       "      <td>2</td>\n",
       "      <td>$19.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Melbourne Farm</td>\n",
       "      <td>Peach</td>\n",
       "      <td>$2.99</td>\n",
       "      <td>1</td>\n",
       "      <td>$2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        farm_name organic_items price_kg quantity_kg subtotal\n",
       "0  Melbourne Farm         Apple    $5.00           1    $5.00\n",
       "1  Melbourne Farm        Orange    $1.99           2    $3.98\n",
       "2  Melbourne Farm    Watermelon    $1.69           3    $5.07\n",
       "3  Melbourne Farm         Mango    $9.56           2   $19.12\n",
       "4  Melbourne Farm         Peach    $2.99           1    $2.99"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text = variable_col_data\n",
    "pattern = r\"\\[([^\\]:]+):([^]]+)\\]\"\n",
    "matches = re.findall(pattern, text, flags=re.DOTALL)\n",
    "\n",
    "data = {}\n",
    "max_len = 0\n",
    "\n",
    "# 2) Split each matched value on \"|-|\"\n",
    "for key, val in matches:\n",
    "    items = [item.replace(\"***\", \"\").strip()  # optionally remove \"***\"\n",
    "             for item in val.split(\"|-|\")]\n",
    "    data[key.strip()] = items\n",
    "    max_len = max(max_len, len(items))\n",
    "\n",
    "# 3) Build a DataFrame, ensuring all columns have the same length\n",
    "df = pd.DataFrame({\n",
    "    col: values + [None]*(max_len - len(values))  # pad with None if needed\n",
    "    for col, values in data.items()\n",
    "})\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# text = llm_table_data\n",
    "\n",
    "# pattern = r\"\\[(\\w+):([^]]+)\\]\"\n",
    "# matches = re.findall(pattern, text)\n",
    "\n",
    "# data = {}\n",
    "# for col_name, raw_values in matches:\n",
    "#     values = [v.strip() for v in raw_values.split(\"|-|\")]\n",
    "#     data[col_name] = values\n",
    "\n",
    "# # --- Fix or pad mismatched lengths -----------------------------\n",
    "# max_len = max(len(vals) for vals in data.values())\n",
    "# for col_name, vals in data.items():\n",
    "#     if len(vals) < max_len:\n",
    "#         # Append None (or \"\" or some placeholder) to match the maximum length\n",
    "#         vals += [None] * (max_len - len(vals))\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columsn may be changeed due to llm being overhweled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# text = llm_table_data\n",
    "\n",
    "# # 1) Regex pattern to capture things of the form:\n",
    "# #    [column_name: val1 |-| val2 |-| ...]\n",
    "# pattern = r\"\\[(\\w+):([^]]+)\\]\"\n",
    "\n",
    "# # 2) Find all matches; each match is (column_name, \"val1 |-| val2 |-| ...\")\n",
    "# matches = re.findall(pattern, text)\n",
    "\n",
    "# # 3) Build a dictionary { column_name: [list_of_values, ...] }\n",
    "# data = {}\n",
    "# for col_name, raw_values in matches:\n",
    "#     # Remove any extra newlines/spaces and split on \"|-|\"\n",
    "#     values = [v.strip() for v in raw_values.split(\"|-|\")]\n",
    "#     data[col_name] = values\n",
    "\n",
    "# # 4) Create the DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import modules.llm\n",
    "# importlib.reload(modules.llm)\n",
    "\n",
    "\n",
    "# from modules.llm import table_extraction\n",
    "\n",
    "\n",
    "# table_output = table_extraction(pattern_data = pattern_desc_from_image, text_data =extracted_text, model = \"gpt-4o\", openai_client=openai_client)\n",
    "# table_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'table_header': 'Box SPM.1, Table 1: Description and relationship of scenarios and modelled pathways considered across AR6 Working Group reports',\n",
       "  'column_names': ['category_in_wgiii',\n",
       "   'category_description',\n",
       "   'ghg_emissions_scenarios_sspx-y_in_wgi_and_wgii',\n",
       "   'rcpy_in_wgi_and_wgii']}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_in_wgiii',\n",
       " 'category_description',\n",
       " 'ghg_emissions_scenarios_sspx_y_in_wgi_wgii',\n",
       " 'rcpy_in_wgi_wgii']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_in_wgiii',\n",
       " 'ghg_emissions_scenarios_sspx_y_in_wgi_wgii',\n",
       " 'category_description',\n",
       " 'rcpy_in_wgi_wgii']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fields = list(set(results[0]['column_names']))\n",
    "input_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target table Description and relationship of scenarios and modelled pathways considered across AR6 Working Group reports\n",
      "Columns ['category_description', 'category_in_wgiii', 'ghg_emissions_scenarios_sspx_y_in_wgi_wgii', 'rcpy_in_wgi_wgii'] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:55:19,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_description</th>\n",
       "      <th>category_in_wgiii</th>\n",
       "      <th>ghg_emissions_scenarios_sspx_y_in_wgi_wgii</th>\n",
       "      <th>rcpy_in_wgi_wgii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>limit warming to 1.5°C (&gt;50%) with no or limit...</td>\n",
       "      <td>C1</td>\n",
       "      <td>Very low (SSP1-1.9)</td>\n",
       "      <td>RCP2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>return warming to 1.5°C (&gt;50%) after a high ov...</td>\n",
       "      <td>C2</td>\n",
       "      <td>Low (SSP1-2.6)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>limit warming to 2°C (&gt;67%)</td>\n",
       "      <td>C3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limit warming to 2°C (&gt;50%)</td>\n",
       "      <td>C4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>limit warming to 2.5°C (&gt;50%)</td>\n",
       "      <td>C5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>limit warming to 3°C (&gt;50%)</td>\n",
       "      <td>C6</td>\n",
       "      <td>Intermediate (SSP2-4.5)</td>\n",
       "      <td>RCP 4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limit warming to 4°C (&gt;50%)</td>\n",
       "      <td>C7</td>\n",
       "      <td>High (SSP3-7.0)</td>\n",
       "      <td>RCP 8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exceed warming of 4°C (&gt;50%)</td>\n",
       "      <td>C8</td>\n",
       "      <td>Very high (SSP5-8.5)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                category_description category_in_wgiii  \\\n",
       "0  limit warming to 1.5°C (>50%) with no or limit...                C1   \n",
       "1  return warming to 1.5°C (>50%) after a high ov...                C2   \n",
       "2                        limit warming to 2°C (>67%)                C3   \n",
       "3                        limit warming to 2°C (>50%)                C4   \n",
       "4                      limit warming to 2.5°C (>50%)                C5   \n",
       "5                        limit warming to 3°C (>50%)                C6   \n",
       "6                        limit warming to 4°C (>50%)                C7   \n",
       "7                       exceed warming of 4°C (>50%)                C8   \n",
       "\n",
       "  ghg_emissions_scenarios_sspx_y_in_wgi_wgii rcpy_in_wgi_wgii  \n",
       "0                        Very low (SSP1-1.9)           RCP2.6  \n",
       "1                             Low (SSP1-2.6)                   \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                    Intermediate (SSP2-4.5)          RCP 4.5  \n",
       "6                            High (SSP3-7.0)          RCP 8.5  \n",
       "7                       Very high (SSP5-8.5)                   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import create_model\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import llm_parser\n",
    "\n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import variable_extractor_llm\n",
    "\n",
    "\n",
    "# Could targeting tables then extracting from each one by one and then concating be the best way to go ?\n",
    "# how do i identify tables\n",
    "\n",
    "# If user provided then\n",
    "\n",
    "#  pattern = pattern_output,\n",
    "# If no user provided then get a default template\n",
    "\n",
    "# pattern_output = pattern_description_llm(text_input=extracted_text, base64_image = base64_image, open_api_key= open_api_key )\n",
    "\n",
    "\n",
    "# var_list =  variable_extractor_llm(user_text=text_1, text_data=extracted_text, openai_client=openai_client, model='o3-mini') # gpt-4o\n",
    "table_index = 0\n",
    "\n",
    "input_fields = sorted(set(results[table_index]['column_names'])) # in case of dups\n",
    "\n",
    "\n",
    "# Assume these are the field names coming from the front end\n",
    "# input_fields = list(set(var_list))\n",
    "\n",
    "# input_fields.append('table_number')  # To differential tables\n",
    "# print(input_fields)\n",
    "\n",
    "#   Build a dictionary defining the field names and their types.\n",
    "#  I will assume each field required a list of strings.\n",
    "field_definitions = {field: (list[str], ...) for field in input_fields}\n",
    "\n",
    "# Dynamically create a new Pydantic model \n",
    "dynamic_structured_output_class = create_model('structured_output', **field_definitions)\n",
    "\n",
    "target_table = results[table_index]['table_header']\n",
    "print(f\"Target table {target_table}\")\n",
    "print(f\"Columns {input_fields} \")\n",
    "\n",
    "completion = llm_parser(user_text = user_text, \n",
    "                        target_table=target_table,\n",
    "                        target_variables= input_fields,\n",
    "                        openai_client = openai_client,\n",
    "                        pattern=parsing_rules,\n",
    "                        text_document=extracted_text,\n",
    "                        response_format=dynamic_structured_output_class,\n",
    "                        model='gpt-4o') # o3-mini, gpt-4o\n",
    "\n",
    "out  = completion.choices[0].message.content\n",
    "\n",
    "data = json.loads(out)\n",
    "\n",
    "# To ensure all columns are of the same length\n",
    "# Determine the maximum length among the arrays\n",
    "max_len = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Pad each list to have the same length\n",
    "for key, lst in data.items():\n",
    "    if len(lst) < max_len:\n",
    "        lst.extend([None] * (max_len - len(lst)))\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df # ensure columsn returnd are ascii clean white spaces\n",
    "\n",
    "#error handling try and except \n",
    "# Perhaps retry when JSON error happens\n",
    "# Factorise table numbers. Sometimes i can choose 2 with no other tables present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Description and relationship of scenarios and modelled pathways considered across AR6 Working Group reports'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv=None):\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            extracted_tables = page.extract_tables()\n",
    "            for table in extracted_tables:\n",
    "                tables.append(pd.DataFrame(table))\n",
    "    \n",
    "    # Combine tables into one DataFrame if needed\n",
    "    if tables:\n",
    "        df = pd.concat(tables, ignore_index=True)\n",
    "        if output_csv:\n",
    "            df.to_csv(output_csv, index=False)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "\n",
    "output_csv = \"output.csv\"  # Optional: specify a CSV file to save the extracted table\n",
    "df = extract_tables_from_pdf(pdf_path=pdf_path, output_csv=output_csv)\n",
    "\n",
    "if df is not None:\n",
    "    print(df.head())  # Display first few rows\n",
    "else:\n",
    "    print(\"No tables found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.document import PDF\n",
    "\n",
    "doc = PDF(src=pdf_path, \n",
    "          pages=None,\n",
    "          detect_rotation=False,\n",
    "          pdf_text_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.ocr import TesseractOCR\n",
    "from img2table.document import Image\n",
    "import pytesseract\n",
    "\n",
    "# Instantiation of OCR\n",
    "ocr = TesseractOCR(n_threads=1, lang=\"eng\")\n",
    "\n",
    "# Instantiation of document, either an image or a PDF\n",
    "# doc = Image(pdf_path)\n",
    "\n",
    "# Table extraction\n",
    "extracted_tables = doc.extract_tables(ocr=ocr,\n",
    "                                      implicit_rows=False,\n",
    "                                      implicit_columns=False,\n",
    "                                      borderless_tables=False,\n",
    "                                      min_confidence=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='id_information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_structured_output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dynamic_structured_output_class.__annotations__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  = completion.choices[0].message.content\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON string into a dictionary\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_variable_extractor = \"\"\" \n",
    "\n",
    " You are a skilled data extraction and parsing specialist with expertise in analysing text documents and extracting structured information, these could be from a varity of sources including PDFs and many others. \n",
    "          Your job is to extract data for the provided variable(s) from a text document in line with the user's request and return them in JSON format where each value is associated with each other.  \n",
    "\n",
    " \n",
    "          ''''''''''''''''\n",
    "          User's request: \" I would like to extract the Order No and Model from the pdf document. The order number looks something like this (1051042839) and the model No is an mixture of numbers and letters and looks like this for instance NLOLC1\n",
    "          I would also like to extract the heading which is usually uppercased and above the order and model number. \n",
    "          ''''''''''''''''\n",
    "           \n",
    "          Target variable(s): [model_number, order_number]\n",
    "           \n",
    "text document: ['\\n\\n--- Page 3 ---\\n\\n\\tSTEEL ENCLOSED CONTACTORS\\nOrder No.\\nModel No.\\nAC1 Heating & \\nGeneral Load\\nFluorescent \\nMercury\\nHalogen\\nLED\\nNo. of Poles\\nDimensions HxWxD\\nSTEEL ENCLOSED CONTACTORS\\n1051042857\\nNLCONM25/4\\n25A\\n16A\\n13A\\n25A\\n4 + N\\n184 x 184 x 149mm\\n1051042858\\nNLCONM45/4\\n40A\\n27A\\n22A\\n40A\\n4 + N\\n184 x 184 x 149mm\\n1051042859\\nNLCONM63/3N\\n60A\\n40A\\n32A\\n60A\\n3 + N\\n305 x 285 x 159mm\\n•\\tManufactured in accordance with EN60947-4-1 \\n•\\tIP55 steel enclosure\\n•\\tStandard coil voltage: 230V 50/60Hz\\n•\\tAuxiliary contacts can be fitted\\n•\\tColour RAL7035 light grey\\n•\\tKnockouts top and bottom\\n•\\tAll units are suitable for two wire control i.e. time \\nswitch, thermostat, sensor or other remote controls\\n•\\tSupplied complete with neutral terminals\\nNLCONM100/3N\\n\\tDIRECT ON LINE, REVERSING & \\nSTAR DELTA STARTERS\\n•\\tManufactured in accordance with EN60947-4-1 \\n•\\tIP55 steel enclosure\\n•\\tColour RAL7035 light grey\\n•\\tSurface mounting\\n•\\tStandard coil voltages: 230V or 400V 50/60Hz\\n•\\tBuilt in start/stop and reset push button\\n•\\tHand reset thermal overloads\\n•\\tOverload to be ordered separately\\n•\\tStainless steel pozidrive fixing screws for lid\\n•\\tKnockouts top and bottom\\n•\\tInternal components DIN rail mounted\\nOrder No.\\nModel No.\\nMax Rating\\nControl Voltage\\nDimensions H x W x D\\nType\\nDIRECT ON LINE & REVERSING STARTERS\\n1051042849\\nNLSTM27C\\n7.5kW\\n230V\\n174 x 104 x 134mm\\nDirect on Line\\n£0.00\\n1051042850\\nNLSTM47C\\n7.5kW\\n400V\\n174 x 104 x 134mm\\nDirect on Line\\n£0.00\\n1051042856\\nNLRVM45C\\n5.5kW\\n400V\\n184 x 184 x 149mm\\nReversing\\n£0.00\\n1051042851\\nNLSTM25CSW\\n5.5kW\\n230V\\n184 x 184 x 149mm\\nDOL With Isolator\\n£0.00\\n1051042852\\nNLSTM45CSW\\n5.5kW\\n400V\\n184 x 184 x 149mm\\nDOL With Isolator\\n£0.00\\n1051042854\\nNLSDM415C\\n15kW\\n400V\\n184 x 284 x 149mm\\nStar Delta\\n£0.00\\nNLSTM27C\\nStock items delivered FREE anywhere in UK\\n15 3\\n\\n',\n",
    " '\\n']\n",
    "\n",
    "Output:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"heading\": \"STEEL ENCLOSED CONTACTORS\",\n",
    "    \"order_number\": \"1051042857\",\n",
    "    \"model_number\": \"NLCONM25/4\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"STEEL ENCLOSED CONTACTORS\",\n",
    "    \"order_number\": \"1051042858\",\n",
    "    \"model_number\": \"NLCONM45/4\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"STEEL ENCLOSED CONTACTORS\",\n",
    "    \"order_number\": \"1051042859\",\n",
    "    \"model_number\": \"NLCONM63/3N\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042849\",\n",
    "    \"model_number\": \"NLSTM27C\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042850\",\n",
    "    \"model_number\": \"NLSTM47C\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042856\",\n",
    "    \"model_number\": \"NLRVM45C\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042851\",\n",
    "    \"model_number\": \"NLSTM25CSW\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042852\",\n",
    "    \"model_number\": \"NLSTM45CSW\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042854\",\n",
    "    \"model_number\": \"NLSDM415C\"\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
