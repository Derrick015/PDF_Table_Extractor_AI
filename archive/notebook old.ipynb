{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "\n",
    "openai_client = OpenAI(api_key = open_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply LLM definition of attribute values. \n",
    "import importlib\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import variable_extractor_llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import modules.pdf_extraction\n",
    "importlib.reload(modules.pdf_extraction)\n",
    "from modules.pdf_extraction import extract_text_from_pages, select_pdf_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPUs: {num_cpus}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:11:19,741 - INFO - Opening file selection dialog.\n",
      "2025-02-11 00:11:21,504 - INFO - Selected PDF file: C:/Users/derri/Desktop/page0027.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_path = select_pdf_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15\n",
    "page_no = 0\n",
    "extracted_text = extract_text_from_pages(pdf_path, pages=page_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Number of Tables on the Page: 6\\n\\n2. Table Headers: Metric Male 24° Cone Seat, S Series, DIN 3865 || Metric Female 24° Cone Seat, S Series, DIN 3865 || 90° Metric Female 24° Cone Seat, S Series, DIN 3865 || Standpipe, S Series || 45° Metric Female 24° Cone Seat, S Series, DIN 3865 || 90° Standpipe, S Series\\n\\n3. Rules for Parsing Tables and Headers: \\n   - Identify table headers by recognizing bold or differentiated text followed by structured content.\\n   - Look for sequences where text is followed by columns with repeated patterns (e.g., Thread, To Suit, Hose ID, Size).\\n   - Use contextual key phrases like \"Cone Seat,\" \"Standpipe,\" and angle indicators (e.g., 90°, 45°) to distinguish table groups.\\n   - Text structured in consistent columns over multiple lines often indicates a table.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymupdf \n",
    "## 111\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "import modules.pdf_extraction\n",
    "importlib.reload(modules.llm)\n",
    "importlib.reload(modules.pdf_extraction)\n",
    "\n",
    "from modules.llm import pattern_description_llm, table_extraction\n",
    "from modules.pdf_extraction import get_page_pixel_data\n",
    "\n",
    "\n",
    "base64_image = get_page_pixel_data(pdf_path=pdf_path, page_no=page_no, \n",
    "                    dpi = 500, image_type = 'png')\n",
    "\n",
    "# perhaps let it run twice to make super sure. if the numbers do not match run again and pick the max. If it still does not work then just pick one\n",
    "pattern_desc_from_image = pattern_description_llm(text_input = extracted_text, model='gpt-4o',  base64_image = base64_image, open_api_key=open_api_key)\n",
    "\n",
    "pattern_desc_from_image\n",
    "\n",
    "# Function to process each row in parallel\n",
    "# open ai does not seem to have structed output for this image input version.\n",
    "# Ill pass it as text to the next llm# 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the respective variable outputs\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "text = pattern_desc_from_image\n",
    "# 1) Extract the Number of Tables\n",
    "match_num_tables = re.search(r'Number of Tables on the Page:\\s*(\\d+)', text)\n",
    "if match_num_tables:\n",
    "    num_tables = int(match_num_tables.group(1))\n",
    "else:\n",
    "    num_tables = None  # or handle error\n",
    "\n",
    "# 2) Extract the Table Headers\n",
    "#    We'll grab everything after \"Table Headers:\" until the line \"3. Rules\" begins\n",
    "match_headers = re.search(r'Table Headers:\\s*(.*?)\\s*\\n\\s*3\\.', text, re.DOTALL)\n",
    "if match_headers:\n",
    "    headers_text = match_headers.group(1)\n",
    "    # Split on '||' to get individual headers\n",
    "    table_headers = [h.strip() for h in headers_text.split('||')]\n",
    "else:\n",
    "    table_headers = []\n",
    "\n",
    "# 3) Extract the Rules for Parsing Tables and Headers\n",
    "#    We'll capture everything after \"3. Rules for Parsing Tables and Headers:\" until the end\n",
    "match_rules = re.search(r'3\\. Rules for Parsing Tables and Headers:\\s*(.*)', text, re.DOTALL)\n",
    "if match_rules:\n",
    "    parsing_rules = match_rules.group(1).strip()\n",
    "else:\n",
    "    parsing_rules = \"\"\n",
    "\n",
    "# # Print or use these variables as needed\n",
    "# print(\"Number of Tables:\", num_tables)\n",
    "# print(\"Table Headers:\", table_headers)\n",
    "# print(\"Rules for Parsing Tables and Headers:\\n\", parsing_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'``````````````````````\\nindex: [0], table_header or descriptor: [Metric Male 24° Cone Seat, S Series, DIN 3865], column_names: [0309, thread, to_suit_hose_id, size]\\nindex: [1], table_header or descriptor: [Metric Female 24° Cone Seat, S Series, DIN 3865], column_names: [0309, thread, to_suit_hose_id, size]\\nindex: [2], table_header or descriptor: [90° Metric Female 24° Cone Seat, S Series, DIN 3865], column_names: [0309, thread, to_suit_hose_id, size]\\nindex: [3], table_header or descriptor: [Standpipe, S Series], column_names: [0309, od_mm, to_suit_hose_id]\\nindex: [4], table_header or descriptor: [45° Metric Female 24° Cone Seat, S Series, DIN 3865], column_names: [0309, thread, to_suit_hose_id, size]\\nindex: [5], table_header or descriptor: [90° Standpipe, S Series], column_names: [0309, od_mm, to_suit_hose_id]\\n``````````````````````'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerical columns as an additional feature\n",
    "\n",
    "user_text='Extract all the data from the table'\n",
    "\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import vision_column_llm_parser\n",
    "# use user input to determine table of interst\n",
    "# variable_col_data = vision_column_llm_parser(user_text='Extract all data from the table i also want a column which tells me when the bend radius is above 1000',\n",
    "#                                     table_to_target= table_headers[0],\n",
    "#                                     base64_image=base64_image,\n",
    "#                                     open_api_key=open_api_key)\n",
    "\n",
    "variable_col_data = vision_column_llm_parser(user_text=user_text,\n",
    "                                   text_input= extracted_text,\n",
    "                                    table_to_target= headers_text,\n",
    "                                    base64_image=base64_image,\n",
    "                                    open_api_key=open_api_key)\n",
    "variable_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # Your text\n",
    "# text =variable_col_data\n",
    "\n",
    "# pattern = r'index:\\s*\\[(\\d+)\\].*?column_names:\\s*\\[(.*?)\\]'\n",
    "# matches = re.findall(pattern, text)\n",
    "\n",
    "# results = []\n",
    "# for index_str, columns_str in matches:\n",
    "#     index_value = int(index_str)\n",
    "    \n",
    "#     # 1) Strip any extra whitespace\n",
    "#     # 2) Then remove leading/trailing brackets (e.g. \"[...\" or \"...]\")\n",
    "#     columns_str = columns_str.strip().strip(\"[]\")\n",
    "    \n",
    "#     # Now split on commas to get a proper list\n",
    "#     columns_list = [col.strip() for col in columns_str.split(',')]\n",
    "    \n",
    "#     # Fetch the correct table_header using index\n",
    "#     header = table_headers[index_value]\n",
    "    \n",
    "#     results.append({\n",
    "#         \"index\": index_value,\n",
    "#         \"table_header\": header,\n",
    "#         \"column_names\": columns_list\n",
    "#     })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(results[0]['column_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = variable_col_data\n",
    "pattern = r'index:\\s*\\[(\\d+)\\].*?column_names:\\s*\\[(.*?)\\]'\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "results = []\n",
    "for index_str, columns_str in matches:\n",
    "    index_value = int(index_str)\n",
    "    columns_list = [col.strip() for col in columns_str.split(',')]\n",
    "    \n",
    "    # Use the table_headers list to fetch the header based on index\n",
    "    header = table_headers[index_value]\n",
    "    \n",
    "    results.append({\n",
    "        \"index\": index_value,\n",
    "        \"table_header\": header,\n",
    "        \"column_names\": columns_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import importlib\n",
    "# import modules.llm\n",
    "# importlib.reload(modules.llm)\n",
    "# from modules.llm import variable_extractor_llm\n",
    "\n",
    "# var_list =  variable_extractor_llm(user_text= 'return every column in the table',\n",
    "#                                     text_data=extracted_text, \n",
    "#                                     target_table= table_headers[2],\n",
    "#                                     pattern =parsing_rules,\n",
    "#                                     openai_client=openai_client, \n",
    "#                                     model='gpt-4o') # gpt-4o\n",
    "# var_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metric Male 24° Cone Seat, S Series, DIN 3865'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_index = 0\n",
    "table_headers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0309', 'size', 'thread', 'to_suit_hose_id']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fields = sorted(set(results[table_index]['column_names'])) # in case of dups\n",
    "input_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To extract the data from the specified table \"Metric Male 24° Cone Seat, S Series, DIN 3865\", and return it in the structured format, I\\'ll focus on the columns [\\'0309\\', \\'size\\', \\'thread\\', \\'to_suit_hose_id\\'].\\n\\nHere is the extracted information:\\n\\n``````````````````````````\\n\\n[0309: HMMS03-M16CF |-| HMMS04-M14CF |-| HMMS04-M16CF |-| HMMS04-M18CF |-| HMMS05-M18CF |-| HMMS05-M20CF |-| HMMS06-M18CF |-| HMMS06-M20CF |-| HMMS06-M22CF |-| HMMS06-M24CF |-| HMMS08-M24CF |-| HMMS10-M30CF |-| HMMS12-M30CF |-| HMMS12-M36CF |-| HMMS16-M36CF |-| HMMS16-M42CF |-| HMMS20-M42CF |-| HMMS20-M52CF |-| HMMS24-M52CF],\\n\\n[thread: M16 x 1.5 |-| M14 x 1.5 |-| M16 x 1.5 |-| M18 x 1.5 |-| M18 x 1.5 |-| M20 x 1.5 |-| M18 x 1.5 |-| M20 x 1.5 |-| M22 x 1.5 |-| M24 x 1.5 |-| M24 x 1.5 |-| M30 x 2 |-| M30 x 2 |-| M36 x 2 |-| M36 x 1.5 |-| M42 x 2 |-| M42 x 2 |-| M52 x 2 |-| M52 x 2],\\n\\n[to_suit_hose_id: 3/16” |-| 1/4” |-| 1/4” |-| 1/4” |-| 5/16” |-| 5/16” |-| 3/8” |-| 3/8” |-| 3/8” |-| 3/8” |-| 1/2” |-| 5/8” |-| 3/4” |-| 3/4” |-| 1” |-| 1” |-| 1.1/4” |-| 1.1/4” |-| 1.1/2”],\\n\\n[size: 8S |-| 6S |-| 8S |-| 10S |-| 10S |-| 12S |-| 10S |-| 12S |-| 14S |-| 16S |-| 16S |-| 20S |-| 20S |-| 25S |-| 25S |-| 30S |-| 30S |-| 38S |-| 38S]\\n\\n``````````````````````````'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import vision_llm_parser\n",
    "# use user input to determine table of interst\n",
    "variable_col_data = vision_llm_parser(user_text=user_text,\n",
    "                                   text_input= extracted_text,\n",
    "                                   columns=input_fields,\n",
    "                                    table_to_target= table_headers[0],\n",
    "                                    base64_image=base64_image,\n",
    "                                    open_api_key=open_api_key)\n",
    "variable_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0309</th>\n",
       "      <th>thread</th>\n",
       "      <th>to_suit_hose_id</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HMMS03-M16CF</td>\n",
       "      <td>M16 x 1.5</td>\n",
       "      <td>3/16”</td>\n",
       "      <td>8S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HMMS04-M14CF</td>\n",
       "      <td>M14 x 1.5</td>\n",
       "      <td>1/4”</td>\n",
       "      <td>6S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HMMS04-M16CF</td>\n",
       "      <td>M16 x 1.5</td>\n",
       "      <td>1/4”</td>\n",
       "      <td>8S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HMMS04-M18CF</td>\n",
       "      <td>M18 x 1.5</td>\n",
       "      <td>1/4”</td>\n",
       "      <td>10S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HMMS05-M18CF</td>\n",
       "      <td>M18 x 1.5</td>\n",
       "      <td>5/16”</td>\n",
       "      <td>10S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HMMS05-M20CF</td>\n",
       "      <td>M20 x 1.5</td>\n",
       "      <td>5/16”</td>\n",
       "      <td>12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HMMS06-M18CF</td>\n",
       "      <td>M18 x 1.5</td>\n",
       "      <td>3/8”</td>\n",
       "      <td>10S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HMMS06-M20CF</td>\n",
       "      <td>M20 x 1.5</td>\n",
       "      <td>3/8”</td>\n",
       "      <td>12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HMMS06-M22CF</td>\n",
       "      <td>M22 x 1.5</td>\n",
       "      <td>3/8”</td>\n",
       "      <td>14S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HMMS06-M24CF</td>\n",
       "      <td>M24 x 1.5</td>\n",
       "      <td>3/8”</td>\n",
       "      <td>16S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HMMS08-M24CF</td>\n",
       "      <td>M24 x 1.5</td>\n",
       "      <td>1/2”</td>\n",
       "      <td>16S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HMMS10-M30CF</td>\n",
       "      <td>M30 x 2</td>\n",
       "      <td>5/8”</td>\n",
       "      <td>20S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HMMS12-M30CF</td>\n",
       "      <td>M30 x 2</td>\n",
       "      <td>3/4”</td>\n",
       "      <td>20S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HMMS12-M36CF</td>\n",
       "      <td>M36 x 2</td>\n",
       "      <td>3/4”</td>\n",
       "      <td>25S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HMMS16-M36CF</td>\n",
       "      <td>M36 x 1.5</td>\n",
       "      <td>1”</td>\n",
       "      <td>25S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HMMS16-M42CF</td>\n",
       "      <td>M42 x 2</td>\n",
       "      <td>1”</td>\n",
       "      <td>30S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HMMS20-M42CF</td>\n",
       "      <td>M42 x 2</td>\n",
       "      <td>1.1/4”</td>\n",
       "      <td>30S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HMMS20-M52CF</td>\n",
       "      <td>M52 x 2</td>\n",
       "      <td>1.1/4”</td>\n",
       "      <td>38S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HMMS24-M52CF</td>\n",
       "      <td>M52 x 2</td>\n",
       "      <td>1.1/2”</td>\n",
       "      <td>38S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0309     thread to_suit_hose_id size\n",
       "0   HMMS03-M16CF  M16 x 1.5           3/16”   8S\n",
       "1   HMMS04-M14CF  M14 x 1.5            1/4”   6S\n",
       "2   HMMS04-M16CF  M16 x 1.5            1/4”   8S\n",
       "3   HMMS04-M18CF  M18 x 1.5            1/4”  10S\n",
       "4   HMMS05-M18CF  M18 x 1.5           5/16”  10S\n",
       "5   HMMS05-M20CF  M20 x 1.5           5/16”  12S\n",
       "6   HMMS06-M18CF  M18 x 1.5            3/8”  10S\n",
       "7   HMMS06-M20CF  M20 x 1.5            3/8”  12S\n",
       "8   HMMS06-M22CF  M22 x 1.5            3/8”  14S\n",
       "9   HMMS06-M24CF  M24 x 1.5            3/8”  16S\n",
       "10  HMMS08-M24CF  M24 x 1.5            1/2”  16S\n",
       "11  HMMS10-M30CF    M30 x 2            5/8”  20S\n",
       "12  HMMS12-M30CF    M30 x 2            3/4”  20S\n",
       "13  HMMS12-M36CF    M36 x 2            3/4”  25S\n",
       "14  HMMS16-M36CF  M36 x 1.5              1”  25S\n",
       "15  HMMS16-M42CF    M42 x 2              1”  30S\n",
       "16  HMMS20-M42CF    M42 x 2          1.1/4”  30S\n",
       "17  HMMS20-M52CF    M52 x 2          1.1/4”  38S\n",
       "18  HMMS24-M52CF    M52 x 2          1.1/2”  38S"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text = variable_col_data\n",
    "pattern = r\"\\[([^\\]:]+):([^]]+)\\]\"\n",
    "matches = re.findall(pattern, text, flags=re.DOTALL)\n",
    "\n",
    "data = {}\n",
    "max_len = 0\n",
    "\n",
    "# 2) Split each matched value on \"|-|\"\n",
    "for key, val in matches:\n",
    "    items = [item.replace(\"***\", \"\").strip()  # optionally remove \"***\"\n",
    "             for item in val.split(\"|-|\")]\n",
    "    data[key.strip()] = items\n",
    "    max_len = max(max_len, len(items))\n",
    "\n",
    "# 3) Build a DataFrame, ensuring all columns have the same length\n",
    "df = pd.DataFrame({\n",
    "    col: values + [None]*(max_len - len(values))  # pad with None if needed\n",
    "    for col, values in data.items()\n",
    "})\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# text = llm_table_data\n",
    "\n",
    "# pattern = r\"\\[(\\w+):([^]]+)\\]\"\n",
    "# matches = re.findall(pattern, text)\n",
    "\n",
    "# data = {}\n",
    "# for col_name, raw_values in matches:\n",
    "#     values = [v.strip() for v in raw_values.split(\"|-|\")]\n",
    "#     data[col_name] = values\n",
    "\n",
    "# # --- Fix or pad mismatched lengths -----------------------------\n",
    "# max_len = max(len(vals) for vals in data.values())\n",
    "# for col_name, vals in data.items():\n",
    "#     if len(vals) < max_len:\n",
    "#         # Append None (or \"\" or some placeholder) to match the maximum length\n",
    "#         vals += [None] * (max_len - len(vals))\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columsn may be changeed due to llm being overhweled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# text = llm_table_data\n",
    "\n",
    "# # 1) Regex pattern to capture things of the form:\n",
    "# #    [column_name: val1 |-| val2 |-| ...]\n",
    "# pattern = r\"\\[(\\w+):([^]]+)\\]\"\n",
    "\n",
    "# # 2) Find all matches; each match is (column_name, \"val1 |-| val2 |-| ...\")\n",
    "# matches = re.findall(pattern, text)\n",
    "\n",
    "# # 3) Build a dictionary { column_name: [list_of_values, ...] }\n",
    "# data = {}\n",
    "# for col_name, raw_values in matches:\n",
    "#     # Remove any extra newlines/spaces and split on \"|-|\"\n",
    "#     values = [v.strip() for v in raw_values.split(\"|-|\")]\n",
    "#     data[col_name] = values\n",
    "\n",
    "# # 4) Create the DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import modules.llm\n",
    "# importlib.reload(modules.llm)\n",
    "\n",
    "\n",
    "# from modules.llm import table_extraction\n",
    "\n",
    "\n",
    "# table_output = table_extraction(pattern_data = pattern_desc_from_image, text_data =extracted_text, model = \"gpt-4o\", openai_client=openai_client)\n",
    "# table_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'table_header': 'Box SPM.1, Table 1: Description and relationship of scenarios and modelled pathways considered across AR6 Working Group reports',\n",
       "  'column_names': ['category_in_wgiii',\n",
       "   'category_description',\n",
       "   'ghg_emissions_scenarios_sspx-y_in_wgi_and_wgii',\n",
       "   'rcpy_in_wgi_and_wgii']}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_in_wgiii',\n",
       " 'category_description',\n",
       " 'ghg_emissions_scenarios_sspx_y_in_wgi_wgii',\n",
       " 'rcpy_in_wgi_wgii']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_in_wgiii',\n",
       " 'ghg_emissions_scenarios_sspx_y_in_wgi_wgii',\n",
       " 'category_description',\n",
       " 'rcpy_in_wgi_wgii']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fields = list(set(results[0]['column_names']))\n",
    "input_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target table Description and relationship of scenarios and modelled pathways considered across AR6 Working Group reports\n",
      "Columns ['category_description', 'category_in_wgiii', 'ghg_emissions_scenarios_sspx_y_in_wgi_wgii', 'rcpy_in_wgi_wgii'] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:55:19,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_description</th>\n",
       "      <th>category_in_wgiii</th>\n",
       "      <th>ghg_emissions_scenarios_sspx_y_in_wgi_wgii</th>\n",
       "      <th>rcpy_in_wgi_wgii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>limit warming to 1.5°C (&gt;50%) with no or limit...</td>\n",
       "      <td>C1</td>\n",
       "      <td>Very low (SSP1-1.9)</td>\n",
       "      <td>RCP2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>return warming to 1.5°C (&gt;50%) after a high ov...</td>\n",
       "      <td>C2</td>\n",
       "      <td>Low (SSP1-2.6)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>limit warming to 2°C (&gt;67%)</td>\n",
       "      <td>C3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limit warming to 2°C (&gt;50%)</td>\n",
       "      <td>C4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>limit warming to 2.5°C (&gt;50%)</td>\n",
       "      <td>C5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>limit warming to 3°C (&gt;50%)</td>\n",
       "      <td>C6</td>\n",
       "      <td>Intermediate (SSP2-4.5)</td>\n",
       "      <td>RCP 4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limit warming to 4°C (&gt;50%)</td>\n",
       "      <td>C7</td>\n",
       "      <td>High (SSP3-7.0)</td>\n",
       "      <td>RCP 8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exceed warming of 4°C (&gt;50%)</td>\n",
       "      <td>C8</td>\n",
       "      <td>Very high (SSP5-8.5)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                category_description category_in_wgiii  \\\n",
       "0  limit warming to 1.5°C (>50%) with no or limit...                C1   \n",
       "1  return warming to 1.5°C (>50%) after a high ov...                C2   \n",
       "2                        limit warming to 2°C (>67%)                C3   \n",
       "3                        limit warming to 2°C (>50%)                C4   \n",
       "4                      limit warming to 2.5°C (>50%)                C5   \n",
       "5                        limit warming to 3°C (>50%)                C6   \n",
       "6                        limit warming to 4°C (>50%)                C7   \n",
       "7                       exceed warming of 4°C (>50%)                C8   \n",
       "\n",
       "  ghg_emissions_scenarios_sspx_y_in_wgi_wgii rcpy_in_wgi_wgii  \n",
       "0                        Very low (SSP1-1.9)           RCP2.6  \n",
       "1                             Low (SSP1-2.6)                   \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                    Intermediate (SSP2-4.5)          RCP 4.5  \n",
       "6                            High (SSP3-7.0)          RCP 8.5  \n",
       "7                       Very high (SSP5-8.5)                   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import create_model\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import llm_parser\n",
    "\n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import variable_extractor_llm\n",
    "\n",
    "\n",
    "# Could targeting tables then extracting from each one by one and then concating be the best way to go ?\n",
    "# how do i identify tables\n",
    "\n",
    "# If user provided then\n",
    "\n",
    "#  pattern = pattern_output,\n",
    "# If no user provided then get a default template\n",
    "\n",
    "# pattern_output = pattern_description_llm(text_input=extracted_text, base64_image = base64_image, open_api_key= open_api_key )\n",
    "\n",
    "\n",
    "# var_list =  variable_extractor_llm(user_text=text_1, text_data=extracted_text, openai_client=openai_client, model='o3-mini') # gpt-4o\n",
    "table_index = 0\n",
    "\n",
    "input_fields = sorted(set(results[table_index]['column_names'])) # in case of dups\n",
    "\n",
    "\n",
    "# Assume these are the field names coming from the front end\n",
    "# input_fields = list(set(var_list))\n",
    "\n",
    "# input_fields.append('table_number')  # To differential tables\n",
    "# print(input_fields)\n",
    "\n",
    "#   Build a dictionary defining the field names and their types.\n",
    "#  I will assume each field required a list of strings.\n",
    "field_definitions = {field: (list[str], ...) for field in input_fields}\n",
    "\n",
    "# Dynamically create a new Pydantic model \n",
    "dynamic_structured_output_class = create_model('structured_output', **field_definitions)\n",
    "\n",
    "target_table = results[table_index]['table_header']\n",
    "print(f\"Target table {target_table}\")\n",
    "print(f\"Columns {input_fields} \")\n",
    "\n",
    "completion = llm_parser(user_text = user_text, \n",
    "                        target_table=target_table,\n",
    "                        target_variables= input_fields,\n",
    "                        openai_client = openai_client,\n",
    "                        pattern=parsing_rules,\n",
    "                        text_document=extracted_text,\n",
    "                        response_format=dynamic_structured_output_class,\n",
    "                        model='gpt-4o') # o3-mini, gpt-4o\n",
    "\n",
    "out  = completion.choices[0].message.content\n",
    "\n",
    "data = json.loads(out)\n",
    "\n",
    "# To ensure all columns are of the same length\n",
    "# Determine the maximum length among the arrays\n",
    "max_len = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Pad each list to have the same length\n",
    "for key, lst in data.items():\n",
    "    if len(lst) < max_len:\n",
    "        lst.extend([None] * (max_len - len(lst)))\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df # ensure columsn returnd are ascii clean white spaces\n",
    "\n",
    "#error handling try and except \n",
    "# Perhaps retry when JSON error happens\n",
    "# Factorise table numbers. Sometimes i can choose 2 with no other tables present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Description and relationship of scenarios and modelled pathways considered across AR6 Working Group reports'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv=None):\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            extracted_tables = page.extract_tables()\n",
    "            for table in extracted_tables:\n",
    "                tables.append(pd.DataFrame(table))\n",
    "    \n",
    "    # Combine tables into one DataFrame if needed\n",
    "    if tables:\n",
    "        df = pd.concat(tables, ignore_index=True)\n",
    "        if output_csv:\n",
    "            df.to_csv(output_csv, index=False)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "\n",
    "output_csv = \"output.csv\"  # Optional: specify a CSV file to save the extracted table\n",
    "df = extract_tables_from_pdf(pdf_path=pdf_path, output_csv=output_csv)\n",
    "\n",
    "if df is not None:\n",
    "    print(df.head())  # Display first few rows\n",
    "else:\n",
    "    print(\"No tables found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.document import PDF\n",
    "\n",
    "doc = PDF(src=pdf_path, \n",
    "          pages=None,\n",
    "          detect_rotation=False,\n",
    "          pdf_text_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.ocr import TesseractOCR\n",
    "from img2table.document import Image\n",
    "import pytesseract\n",
    "\n",
    "# Instantiation of OCR\n",
    "ocr = TesseractOCR(n_threads=1, lang=\"eng\")\n",
    "\n",
    "# Instantiation of document, either an image or a PDF\n",
    "# doc = Image(pdf_path)\n",
    "\n",
    "# Table extraction\n",
    "extracted_tables = doc.extract_tables(ocr=ocr,\n",
    "                                      implicit_rows=False,\n",
    "                                      implicit_columns=False,\n",
    "                                      borderless_tables=False,\n",
    "                                      min_confidence=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='id_information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_structured_output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dynamic_structured_output_class.__annotations__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  = completion.choices[0].message.content\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON string into a dictionary\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_variable_extractor = \"\"\" \n",
    "\n",
    " You are a skilled data extraction and parsing specialist with expertise in analysing text documents and extracting structured information, these could be from a varity of sources including PDFs and many others. \n",
    "          Your job is to extract data for the provided variable(s) from a text document in line with the user's request and return them in JSON format where each value is associated with each other.  \n",
    "\n",
    " \n",
    "          ''''''''''''''''\n",
    "          User's request: \" I would like to extract the Order No and Model from the pdf document. The order number looks something like this (1051042839) and the model No is an mixture of numbers and letters and looks like this for instance NLOLC1\n",
    "          I would also like to extract the heading which is usually uppercased and above the order and model number. \n",
    "          ''''''''''''''''\n",
    "           \n",
    "          Target variable(s): [model_number, order_number]\n",
    "           \n",
    "text document: ['\\n\\n--- Page 3 ---\\n\\n\\tSTEEL ENCLOSED CONTACTORS\\nOrder No.\\nModel No.\\nAC1 Heating & \\nGeneral Load\\nFluorescent \\nMercury\\nHalogen\\nLED\\nNo. of Poles\\nDimensions HxWxD\\nSTEEL ENCLOSED CONTACTORS\\n1051042857\\nNLCONM25/4\\n25A\\n16A\\n13A\\n25A\\n4 + N\\n184 x 184 x 149mm\\n1051042858\\nNLCONM45/4\\n40A\\n27A\\n22A\\n40A\\n4 + N\\n184 x 184 x 149mm\\n1051042859\\nNLCONM63/3N\\n60A\\n40A\\n32A\\n60A\\n3 + N\\n305 x 285 x 159mm\\n•\\tManufactured in accordance with EN60947-4-1 \\n•\\tIP55 steel enclosure\\n•\\tStandard coil voltage: 230V 50/60Hz\\n•\\tAuxiliary contacts can be fitted\\n•\\tColour RAL7035 light grey\\n•\\tKnockouts top and bottom\\n•\\tAll units are suitable for two wire control i.e. time \\nswitch, thermostat, sensor or other remote controls\\n•\\tSupplied complete with neutral terminals\\nNLCONM100/3N\\n\\tDIRECT ON LINE, REVERSING & \\nSTAR DELTA STARTERS\\n•\\tManufactured in accordance with EN60947-4-1 \\n•\\tIP55 steel enclosure\\n•\\tColour RAL7035 light grey\\n•\\tSurface mounting\\n•\\tStandard coil voltages: 230V or 400V 50/60Hz\\n•\\tBuilt in start/stop and reset push button\\n•\\tHand reset thermal overloads\\n•\\tOverload to be ordered separately\\n•\\tStainless steel pozidrive fixing screws for lid\\n•\\tKnockouts top and bottom\\n•\\tInternal components DIN rail mounted\\nOrder No.\\nModel No.\\nMax Rating\\nControl Voltage\\nDimensions H x W x D\\nType\\nDIRECT ON LINE & REVERSING STARTERS\\n1051042849\\nNLSTM27C\\n7.5kW\\n230V\\n174 x 104 x 134mm\\nDirect on Line\\n£0.00\\n1051042850\\nNLSTM47C\\n7.5kW\\n400V\\n174 x 104 x 134mm\\nDirect on Line\\n£0.00\\n1051042856\\nNLRVM45C\\n5.5kW\\n400V\\n184 x 184 x 149mm\\nReversing\\n£0.00\\n1051042851\\nNLSTM25CSW\\n5.5kW\\n230V\\n184 x 184 x 149mm\\nDOL With Isolator\\n£0.00\\n1051042852\\nNLSTM45CSW\\n5.5kW\\n400V\\n184 x 184 x 149mm\\nDOL With Isolator\\n£0.00\\n1051042854\\nNLSDM415C\\n15kW\\n400V\\n184 x 284 x 149mm\\nStar Delta\\n£0.00\\nNLSTM27C\\nStock items delivered FREE anywhere in UK\\n15 3\\n\\n',\n",
    " '\\n']\n",
    "\n",
    "Output:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"heading\": \"STEEL ENCLOSED CONTACTORS\",\n",
    "    \"order_number\": \"1051042857\",\n",
    "    \"model_number\": \"NLCONM25/4\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"STEEL ENCLOSED CONTACTORS\",\n",
    "    \"order_number\": \"1051042858\",\n",
    "    \"model_number\": \"NLCONM45/4\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"STEEL ENCLOSED CONTACTORS\",\n",
    "    \"order_number\": \"1051042859\",\n",
    "    \"model_number\": \"NLCONM63/3N\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042849\",\n",
    "    \"model_number\": \"NLSTM27C\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042850\",\n",
    "    \"model_number\": \"NLSTM47C\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042856\",\n",
    "    \"model_number\": \"NLRVM45C\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042851\",\n",
    "    \"model_number\": \"NLSTM25CSW\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042852\",\n",
    "    \"model_number\": \"NLSTM45CSW\"\n",
    "  },\n",
    "  {\n",
    "    \"heading\": \"DIRECT ON LINE, REVERSING & STAR DELTA STARTERS\",\n",
    "    \"order_number\": \"1051042854\",\n",
    "    \"model_number\": \"NLSDM415C\"\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
