{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "\n",
    "openai_client = OpenAI(api_key = open_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 19:43:44,456 - INFO - Opening file selection dialog.\n",
      "2025-02-26 19:43:50,400 - INFO - Selected PDF file: C:/Users/derri/Downloads/page0025.pdf\n"
     ]
    }
   ],
   "source": [
    "# 15\n",
    "\n",
    "from modules.pdf_extraction import select_pdf_file\n",
    "from modules.pdf_extraction import extract_text_from_pages\n",
    "\n",
    "pdf_path = select_pdf_file()\n",
    "page_no = 0\n",
    "extracted_text = extract_text_from_pages(pdf_path, pages=page_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf \n",
    "## 111\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "import importlib\n",
    "import modules.llm\n",
    "import modules.pdf_extraction\n",
    "\n",
    "\n",
    "from modules.pdf_extraction import get_page_pixel_data\n",
    "\n",
    "\n",
    "\n",
    "# this may have to happen on a page by page basis\n",
    "\n",
    "base64_image = get_page_pixel_data(pdf_path=pdf_path, page_no=page_no, \n",
    "                    dpi = 500, image_type = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf\n",
    "\n",
    "# # Open some document, for example a PDF (could also be EPUB, XPS, etc.)\n",
    "# doc = pymupdf.open(pdf_path)\n",
    "\n",
    "# # Load a desired page. This works via 0-based numbers\n",
    "# page = doc[0]  # this is the first page\n",
    "\n",
    "# # Look for tables on this page and display the table count\n",
    "# tabs = page.find_tables()\n",
    "# num_tables = len(tabs.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.llm\n",
    "importlib.reload(modules.llm)\n",
    "from modules.llm import table_identification_llm\n",
    "\n",
    "output_table_identification_llm = await table_identification_llm(text_input=extracted_text,  base64_image=base64_image, open_api_key=open_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Number of Tables on the Page: 5  \\n\\n2. Table Headers: \"JIC 37° Male Inserts - Top left of the page\" || \"JIC 37° Swivel Female Inserts - Top center of the page\" || \"JIC 37° Female Swept Elbow Inserts - Top right of the page\" || \"JIC 37° Female Swept Elbow Inserts - Bottom left of the page\" || \"JIC 37° Female Compact 90° Elbow Inserts - Bottom right of the page\"\\n\\n3. Table Location for each table: [Table is present in both the image and the text document] || [Table is present in both the image and the text document] || [Table is present in both the image and the text document] || [Table is present in both the image and the text document] || [Table is present in both the image and the text document]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table_identification_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "Initial headers match or same number of tables\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(modules.pdf_extraction)\n",
    "from modules.pdf_extraction import get_validated_table_info\n",
    "num_tables, table_headers, table_location, confidence_score_0 = await get_validated_table_info(text_input=extracted_text, open_api_key=open_api_key, base64_image= base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modules.pdf_extraction import table_identification_llm\n",
    "\n",
    "\n",
    "# output = await table_identification_llm(text_input=extracted_text, base64_image=base64_image, open_api_key=open_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_tables == 0:\n",
    "    raise ValueError(\"No tables found on the page\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in control for no tables found\n",
    "# table_with_index = \" || \".join([f\"index {i}: {header}\" for i, header in enumerate(table_headers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables_data = [f\"[{i}]\" for i in table_headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n--- Page 1 ---\\n\\n19\\n1.01  Hydraulic Hose & Inserts\\nHydraulics\\n1\\nJIC\\n Hexavalent chromium free plating\\nJIC 37¡ Male Inserts\\n0309\\nThread\\nTo Suit Hose ID\\nJM0403CF\\n7/16”\\n3/16”\\nJM0404CF\\n7/16”\\n1/4”\\nJM0504CF\\n1/2”\\n1/4”\\nJM0505CF\\n1/2”\\n5/16”\\nJM0604CF\\n9/16”\\n1/4”\\nJM0605CF\\n9/16”\\n5/16”\\nJM0606CF\\n9/16”\\n3/8”\\nJM0608CF\\n9/16”\\n1/2”\\nJM0805CF\\n3/4”\\n5/16”\\nJM0806CF\\n3/4”\\n3/8”\\nJM0808CF\\n3/4”\\n1/2”\\nJM1006CF\\n7/8”\\n3/8”\\nJM1008CF\\n7/8”\\n1/2”\\nJM1010CF\\n7/8”\\n5/8”\\nJM1012CF\\n7/8”\\n3/4”\\nJM1208CF\\n3/4”\\n1/2”\\nJM1210CF\\n1.1/16”\\n5/8”\\nJM1212CF\\n1.1/16”\\n3/4”\\nJM1216CF\\n1.1/16”\\n1”\\nJM1412CF\\n1.3/16”\\n3/4”\\nJM1416CF\\n1.3/16”\\n1”\\nJM1612CF\\n1.5/16”\\n3/4”\\nJM1616CF\\n1.5/16”\\n1”\\nJM2016CF\\n1.5/8”\\n1”\\nJM2020CF\\n1.5/8”\\n1.1/4”\\nJM2420CF\\n1.7/8”\\n1.1/4”\\nJM2424CF\\n1.7/8”\\n1.1/2”\\nJM3232CF\\n2.1/2”\\n2”\\nJIC 37¡ Swivel Female Inserts\\n0309\\nThread\\nTo Suit Hose ID\\nJF0403CF\\n7/16”\\n3/16”\\nJF0404CF\\n7/16”\\n1/4”\\nJF0406CF\\n7/16”\\n3/8\\nJF0503CF\\n1/2”\\n3/16”\\nJF0504CF\\n1/2”\\n1/4”\\nJF0505CF\\n1/2”\\n5/16”\\nJF0506CF\\n1/2”\\n3/8”\\nJF0604CF\\n9/16”\\n1/4”\\nJF0605CF\\n9/16”\\n5/16”\\nJF0606CF\\n9/16”\\n3/8”\\nJF0805CF\\n3/4”\\n5/16”\\nJF0806CF\\n3/4”\\n3/8”\\nJF0808CF\\n3/4”\\n1/2”\\nJF1006CF\\n7/8”\\n3/8”\\nJF1008CF\\n7/8”\\n1/2”\\nJF1010CF\\n7/8”\\n5/8”\\nJF1012CF\\n7/8”\\n3/4”\\nJF1208CF\\n1.1/16”\\n1/2”\\nJF1210CF\\n1.1/16”\\n5/8”\\nJF1212CF\\n1.1/16”\\n3/4”\\nJF1216CF\\n1.1/16”\\n1”\\nJF1412CF\\n1.3/16”\\n3/4”\\nJF1416CF\\n1.3/16”\\n1”\\nJF1612CF\\n1.5/16”\\n3/4”\\nJF1616CF\\n1.5/16”\\n1”\\nJF2016CF\\n1.5/8”\\n1”\\nJF2020CF\\n1.5/8”\\n1.1/4”\\nJF2420CF\\n1.7/8”\\n1.1/4”\\nJF2424CF\\n1.7/8”\\n1.1/2”\\nJF3232CF\\n2.1/2”\\n2”\\nJIC 37¡ Female Swept Elbow Inserts\\n0309\\nThread\\nTo Suit Hose ID\\nJF049003CF\\n7/16”\\n3/16”\\nJF049004CF\\n7/16”\\n1/4”\\nJF059003CF\\n1/2”\\n3/16”\\nJF059004CF\\n1/2”\\n1/4”\\nJF059005CF\\n1/2”\\n5/16”\\nJF059006CF\\n1/2”\\n3/8”\\nJF069004CF\\n9/16”\\n1/4”\\nJF069005CF\\n9/16”\\n5/16”\\nJF069006CF\\n9/16”\\n3/8”\\nJF089005CF\\n3/4”\\n5/16”\\nJF089006CF\\n3/4”\\n3/8”\\nJF089008CF\\n3/4”\\n1/2”\\nJF109006CF\\n7/8”\\n3/8”\\nJF109008CF\\n7/8”\\n1/2”\\nJF109010CF\\n7/8”\\n5/8”\\nJF109012CF\\n7/8”\\n3/4”\\nJF129008CF\\n1.1/16”\\n1/2”\\nJF129010CF\\n1.1/16”\\n5/8”\\nJF129012CF\\n1.1/16”\\n3/4”\\nJF129016CF\\n1.1/16”\\n1”\\nJF149012CF\\n1.3/16”\\n3/4”\\nJF149016CF\\n1.3/16”\\n1”\\nJF169012CF\\n1.5/16”\\n3/4”\\nJF169016CF\\n1.5/16”\\n1”\\nJF209016CF\\n1.5/8”\\n1”\\nJF209020CF\\n1.5/8”\\n1.1/4”\\nJF249020CF\\n1.7/8”\\n1.1/4”\\nJF249024CF\\n1.7/8”\\n1.1/2”\\nJF329032CF\\n2.1/2”\\n2”\\nJIC 37¡ Female Swept Elbow Inserts\\n0309\\nThread\\nTo Suit Hose ID\\nJF044503CF\\n7/16”\\n3/16”\\nJF044504CF\\n7/16”\\n1/4”\\nJF054504CF\\n1/2”\\n1/4”\\nJF054505CF\\n1/2”\\n5/16”\\nJF054506CF\\n1/2”\\n3/8”\\nJF064504CF\\n9/16”\\n1/4”\\nJF064505CF\\n9/16”\\n5/16”\\nJF064506CF\\n9/16”\\n3/8”\\nJF084506CF\\n3/4”\\n3/8”\\nJF084508CF\\n3/4”\\n1/2”\\nJF104506CF\\n7/8”\\n3/8”\\nJF104508CF\\n7/8”\\n1/2”\\nJF104510CF\\n7/8”\\n5/8”\\n0309\\nThread\\nTo Suit Hose ID\\nJF104512CF\\n7/8”\\n3/4”\\nJF124508CF\\n1.1/16”\\n1/2”\\nJF124510CF\\n1.1/16”\\n5/8”\\nJF124512CF\\n1.1/16”\\n3/4”\\nJF124516CF\\n1.1/16”\\n1”\\nJF144512CF\\n1.3/16”\\n3/4”\\nJF144516CF\\n1.3/16”\\n1”\\nJF164512CF\\n1.5/16”\\n3/4”\\nJF164516CF\\n1.5/16”\\n1”\\nJF204516CF\\n1.5/8”\\n1”\\nJF204520CF\\n1.5/8”\\n1.1/4”\\nJF244524CF\\n1.7/8”\\n1.1/2”\\nJF324532CF\\n2.1/2”\\n2”\\nJIC 37¡ Female Compact \\n90¡ Elbow Inserts\\n0309\\nThread\\nTo Suit Hose ID\\nJF0490K04CF\\n7/16”\\n1/4”\\nJF0690K04CF\\n9/16”\\n1/4”\\nJF0690K06CF\\n9/16”\\n3/8”\\nJF0890K06CF\\n3/4”\\n3/8”\\nJF0890K08CF\\n3/4”\\n1/2”\\nJF1090K08CF\\n7/8”\\n1/2”\\nJF1090K10CF\\n7/8”\\n5/8”\\nJF1290K12CF\\n1.1/16”\\n3/4”\\nJF1690K16CF\\n1.5/16”\\n1”\\nHYDRAULIC HOSE CONNECTORS\\n\\n|-|+++|-|\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0309</th>\n",
       "      <th>Thread</th>\n",
       "      <th>To Suit Hose Id</th>\n",
       "      <th>table_header_descriptor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JM0403CF</td>\n",
       "      <td>7/16”</td>\n",
       "      <td>3/16”</td>\n",
       "      <td>\"JIC 37° Male Inserts - Can be found on the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JM0404CF</td>\n",
       "      <td>7/16”</td>\n",
       "      <td>1/4”</td>\n",
       "      <td>\"JIC 37° Male Inserts - Can be found on the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JM0504CF</td>\n",
       "      <td>1/2”</td>\n",
       "      <td>1/4”</td>\n",
       "      <td>\"JIC 37° Male Inserts - Can be found on the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JM0505CF</td>\n",
       "      <td>1/2”</td>\n",
       "      <td>5/16”</td>\n",
       "      <td>\"JIC 37° Male Inserts - Can be found on the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JM0604CF</td>\n",
       "      <td>9/16”</td>\n",
       "      <td>1/4”</td>\n",
       "      <td>\"JIC 37° Male Inserts - Can be found on the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>JF0890K08CF</td>\n",
       "      <td>3/4”</td>\n",
       "      <td>1/2”</td>\n",
       "      <td>\"JIC 37° Female Compact 90° Elbow Inserts - Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>JF1090K08CF</td>\n",
       "      <td>7/8”</td>\n",
       "      <td>1/2”</td>\n",
       "      <td>\"JIC 37° Female Compact 90° Elbow Inserts - Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>JF1090K10CF</td>\n",
       "      <td>7/8”</td>\n",
       "      <td>5/8”</td>\n",
       "      <td>\"JIC 37° Female Compact 90° Elbow Inserts - Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>JF1290K12CF</td>\n",
       "      <td>1.1/16”</td>\n",
       "      <td>3/4”</td>\n",
       "      <td>\"JIC 37° Female Compact 90° Elbow Inserts - Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>JF1690K16CF</td>\n",
       "      <td>1.5/16”</td>\n",
       "      <td>1”</td>\n",
       "      <td>\"JIC 37° Female Compact 90° Elbow Inserts - Ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0309   Thread To Suit Hose Id  \\\n",
       "0       JM0403CF    7/16”           3/16”   \n",
       "1       JM0404CF    7/16”            1/4”   \n",
       "2       JM0504CF     1/2”            1/4”   \n",
       "3       JM0505CF     1/2”           5/16”   \n",
       "4       JM0604CF    9/16”            1/4”   \n",
       "..           ...      ...             ...   \n",
       "120  JF0890K08CF     3/4”            1/2”   \n",
       "121  JF1090K08CF     7/8”            1/2”   \n",
       "122  JF1090K10CF     7/8”            5/8”   \n",
       "123  JF1290K12CF  1.1/16”            3/4”   \n",
       "124  JF1690K16CF  1.5/16”              1”   \n",
       "\n",
       "                               table_header_descriptor  \n",
       "0    \"JIC 37° Male Inserts - Can be found on the to...  \n",
       "1    \"JIC 37° Male Inserts - Can be found on the to...  \n",
       "2    \"JIC 37° Male Inserts - Can be found on the to...  \n",
       "3    \"JIC 37° Male Inserts - Can be found on the to...  \n",
       "4    \"JIC 37° Male Inserts - Can be found on the to...  \n",
       "..                                                 ...  \n",
       "120  \"JIC 37° Female Compact 90° Elbow Inserts - Ca...  \n",
       "121  \"JIC 37° Female Compact 90° Elbow Inserts - Ca...  \n",
       "122  \"JIC 37° Female Compact 90° Elbow Inserts - Ca...  \n",
       "123  \"JIC 37° Female Compact 90° Elbow Inserts - Ca...  \n",
       "124  \"JIC 37° Female Compact 90° Elbow Inserts - Ca...  \n",
       "\n",
       "[125 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import importlib\n",
    "import modules.pdf_extraction\n",
    "importlib.reload(modules.pdf_extraction)\n",
    "from modules.pdf_extraction import process_tables_to_df\n",
    "\n",
    "\n",
    "user_input = \"I would like to get all the data text from the table\"\n",
    "\n",
    "output_1 = await process_tables_to_df(\n",
    "                     user_text=user_input,\n",
    "                     table_location = table_location,\n",
    "                     table_headers = table_headers,\n",
    "                     extracted_text=extracted_text, \n",
    "                     base64_image=base64_image, \n",
    "                     open_api_key=open_api_key)\n",
    "\n",
    "\n",
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add in try and except for error handling\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import importlib\n",
    "# import modules.llm\n",
    "# importlib.reload(modules.llm)\n",
    "# from modules.llm import vision_llm_parser\n",
    "\n",
    "# user_input = \"I would like to get all the data text from the table\"\n",
    "\n",
    "# output = await vision_llm_parser(\n",
    "#                 user_text=user_input,\n",
    "#                 text_input=extracted_text,\n",
    "#                 table_to_target=table_headers[1],\n",
    "#                 base64_image=base64_image,\n",
    "#                 open_api_key=open_api_key,\n",
    "#                 model='gpt-4o'\n",
    "#             )\n",
    "\n",
    "# # from modules.pdf_extraction import parse_variable_data_to_df\n",
    "# # df_0 = parse_variable_data_to_df(output)\n",
    "# # df_0\n",
    "\n",
    "# # def extract_list_from_string(text):\n",
    "# #     # Find the content between the first [ and last ], including the brackets\n",
    "# #     match = re.search(r'(\\[.*\\])', text, re.DOTALL)\n",
    "# #     if match:\n",
    "# #         # Return the full string including brackets\n",
    "# #         return match.group(1)\n",
    "# #     return None\n",
    "\n",
    "# # extracted_dict = extract_list_from_string(output)\n",
    "\n",
    "\n",
    "# # data = json.loads(extracted_dict)\n",
    "# # df = pd.DataFrame(data)\n",
    "# # df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 20:48:19,294 - INFO - Opening file selection dialog.\n",
      "2025-02-24 20:48:21,790 - INFO - Selected PDF file: C:/Users/derri/Downloads/page0025.pdf\n"
     ]
    }
   ],
   "source": [
    "# pdf_path = select_pdf_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 table(s) on page 0 of C:/Users/derri/Downloads/page0025.pdf\n"
     ]
    }
   ],
   "source": [
    "# import pymupdf\n",
    "\n",
    "# # Open some document, for example a PDF (could also be EPUB, XPS, etc.)\n",
    "# doc = pymupdf.open(pdf_path)\n",
    "\n",
    "# # Load a desired page. This works via 0-based numbers\n",
    "# page = doc[0]  # this is the first page\n",
    "\n",
    "# # Look for tables on this page and display the table count\n",
    "# tabs = page.find_tables()\n",
    "# print(f\"{len(tabs.tables)} table(s) on {page}\")\n",
    "\n",
    "# # We will see a message like \"1 table(s) on page 0 of input.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 21:45:01,138 - INFO - Opening file selection dialog.\n",
      "2025-02-27 21:45:03,431 - INFO - Selected PDF file: C:/Users/derri/Downloads/3 in one.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "Initial headers match or same number of tables\n",
      "8 6\n",
      "No matches found. Returning third run results for table_headers\n",
      "7 8\n",
      "No matches found. Returning third run results for table_headers\n"
     ]
    }
   ],
   "source": [
    "from modules.pdf_extraction import select_pdf_file\n",
    "\n",
    "from modules.pdf_extraction import get_validated_table_info\n",
    "from modules.pdf_extraction import get_page_pixel_data\n",
    "from modules.pdf_extraction import process_tables_to_df\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import os\n",
    "import pymupdf\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# to do.. table names headers can be dupilcated may be helpful to use say table 1,2, etc to deitigusih tem. \n",
    "# use pdf plumber  page.find_tables() and gpt table count for confidence calculation. \n",
    "# the same table can be extraected twice or more if the header is not clear\n",
    "# extract header witout the text \n",
    "\n",
    "file_name = 'test_7'    \n",
    "user_text='Extract all data from the table(s) the header'\n",
    "\n",
    "# 1. Load Credientials\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "# Get the API key from the environment variable\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key = open_api_key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Select PDF file and extract text\n",
    "pdf_path = select_pdf_file()\n",
    "doc = pymupdf.open(pdf_path)\n",
    "total_pages = doc.page_count  # total number of pages in the document\n",
    "page_indices = range(total_pages)\n",
    "\n",
    "# page_indices can be a list of page numbers to process\n",
    "\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "async def process_page():\n",
    "    tasks = []\n",
    "    results_output = []\n",
    "    # Create all tasks first \n",
    "    async with asyncio.TaskGroup() as tg:\n",
    "        for page_no in page_indices:\n",
    "            page = doc.load_page(page_no)\n",
    "            extracted_text = page.get_text()\n",
    "            \n",
    "            # extracted_text = extract_text_from_pages(pdf_path, pages=page_no)\n",
    "            base64_image = get_page_pixel_data(pdf_path=pdf_path, page_no=page_no, \n",
    "                                dpi = 500, image_type = 'png')\n",
    "        \n",
    "            num_tables, table_headers, table_location, confidence_score_0 = await get_validated_table_info(\n",
    "                text_input=extracted_text, \n",
    "                open_api_key=open_api_key, \n",
    "                base64_image=base64_image\n",
    "            )\n",
    "\n",
    "            if num_tables == 0:\n",
    "                print(f\"No tables found on page {page_no + 1}, skipping...\")\n",
    "                continue\n",
    "    \n",
    "            tasks.append(tg.create_task(process_tables_to_df(\n",
    "                table_headers, \n",
    "                table_location,\n",
    "                user_text, \n",
    "                extracted_text, \n",
    "                base64_image, \n",
    "                open_api_key,\n",
    "                page_number=page_no)))\n",
    "            \n",
    "        # Await all tasks to complete\n",
    "        for task in tasks:\n",
    "            results_output.append(await task)\n",
    "    \n",
    "    if not results_output:\n",
    "        raise ValueError(\"No tables found on any of the processed pages\")\n",
    "            \n",
    "    # df_out_1 = pd.concat(results_output, ignore_index=True)\n",
    "    return results_output\n",
    "\n",
    "\n",
    "output_final = await process_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "def write_output_final(output_final, excel_path, option=1, gap_rows=2):\n",
    "    \"\"\"\n",
    "    Writes nested lists of DataFrames (`output_final`) to Excel in 3 different ways.\n",
    "\n",
    "    :param output_final: A list of lists of DataFrames. \n",
    "                        e.g. [\n",
    "                            [df0_0, df0_1, df0_2],  # first \"page\"\n",
    "                            [df1_0, df1_1],        # second \"page\"\n",
    "                            ...\n",
    "                        ]\n",
    "    :param excel_path: Output Excel filename/path\n",
    "    :param option: Choose 1 of 3 write modes:\n",
    "                   1 = Horizontally merge (side-by-side) all DataFrames into one wide table (one sheet)\n",
    "                   2 = Each top-level group on its own sheet, with `gap_rows` blank rows between sub-DataFrames\n",
    "                   3 = Flatten all DataFrames onto one sheet vertically, with `gap_rows` blank rows between them\n",
    "    :param gap_rows: How many blank rows to insert between tables (used in options 2 and 3).\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        \n",
    "        if option == 1:\n",
    "            # ---------------------------------------------------------\n",
    "            # (1) Horizontally merge *all* DataFrames into ONE wide table\n",
    "            # ---------------------------------------------------------\n",
    "            # Flatten the nested list into a single list of DataFrames\n",
    "            all_dfs = list(itertools.chain.from_iterable(output_final))\n",
    "            \n",
    "            # Concatenate them horizontally (side-by-side)\n",
    "            # By default, rows are aligned on the index; \n",
    "            # if DataFrames have different row indices, you may need join='outer' or join='inner'\n",
    "            merged_df = pd.concat(all_dfs, axis=0)\n",
    "            merged_df.to_excel(writer, sheet_name=\"AllTablesMerged\", index=False)\n",
    "            \n",
    "        elif option == 2:\n",
    "            # ---------------------------------------------------------\n",
    "            # (2) Each top-level group on a DIFFERENT sheet,\n",
    "            #     with gap_rows between each sub-DataFrame\n",
    "            # ---------------------------------------------------------\n",
    "            for page_idx, df_group in enumerate(output_final):\n",
    "                # Each top-level group is a \"page\" => one sheet\n",
    "                sheet_name = f\"Page_{page_idx+1}\"\n",
    "                start_row = 0\n",
    "                \n",
    "                for df in df_group:\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "                    # Shift down for the next DF: table rows + header row + gap_rows\n",
    "                    start_row += len(df) + 1 + gap_rows\n",
    "                    \n",
    "        elif option == 3:\n",
    "            # ---------------------------------------------------------\n",
    "            # (3) Flatten all DataFrames on ONE sheet (stacked vertically),\n",
    "            #     with gap_rows rows between each\n",
    "            # ---------------------------------------------------------\n",
    "            \n",
    "            all_dfs = list(itertools.chain.from_iterable(output_final))\n",
    "            \n",
    "            sheet_name = \"AllTablesWithGaps\"\n",
    "            start_row = 0\n",
    "            for df in all_dfs:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "                start_row += len(df) + 1 + gap_rows\n",
    "                \n",
    "        else:\n",
    "            raise ValueError(\"Invalid `option` - must be 1, 2, or 3.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output_final(output_final, excel_path='files/AllTables11.xlsx', option=1, gap_rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import itertools\n",
    "# all_dfs = list(itertools.chain.from_iterable(output_final))\n",
    "# combined_dfs = pd.concat(all_dfs)\n",
    "\n",
    "\n",
    "# combined_dfs['descriptor_label'] = (\n",
    "#     combined_dfs.groupby('page_number')['table_header_descriptor']\n",
    "#     .transform(lambda x: pd.factorize(x)[0] + 1)\n",
    "# )\n",
    "\n",
    "\n",
    "# combined_dfs['page_table'] = (\n",
    "#     'page ' + combined_dfs['page_number'].astype(str) +\n",
    "#     ' table ' + combined_dfs['descriptor_label'].astype(str)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_dict = combined_dfs.groupby('table_header_descriptor')['page_table'].apply(list).to_dict()\n",
    "# mapping_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['table_header_descriptor'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "\n",
    "# all_dfs = list(itertools.chain.from_iterable(output_final))\n",
    "# combined_dfs = pd.concat(all_dfs)\n",
    "# combined_dfs['table_header_descriptor_factorized'], _ = pd.factorize(combined_dfs['table_header_descriptor'])\n",
    "\n",
    "\n",
    "\n",
    "# unique_headers = combined_dfs['table_header_descriptor_factorized'].unique()\n",
    "# header_to_num = {\n",
    "#     header: f\"Page {combined_dfs['page_number'] + 1} Table {i+1}\"\n",
    "#     for i, header in enumerate(unique_headers)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a \"page_table\" label using unique descriptors\n",
    "# unique_headers = df['table_header_descriptor'].unique()\n",
    "# header_to_num = {\n",
    "#     header: f\"Page {df['page_number'] + 1} Table {i+1}\"\n",
    "#     for i, header in enumerate(unique_headers)\n",
    "# }\n",
    "# df['page_table'] = df['table_header_descriptor'].map(header_to_num)\n",
    "\n",
    "# # df.drop(columns=['table_header_descriptor'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write combined tables to excel\n",
    "\n",
    "df_combined = pd.concat(output_final[0], ignore_index=True)\n",
    "df_combined.to_excel(f'files/{file_name}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pdf_extraction import write_split_tables_to_excel\n",
    "\n",
    "# Call the function with output_final[0]\n",
    "write_split_tables_to_excel(output_final[0],output_path='files/test_output.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
