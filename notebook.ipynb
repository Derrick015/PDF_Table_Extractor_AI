{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "\n",
    "openai_client = OpenAI(api_key = open_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pdf_extraction import select_pdf_file\n",
    "\n",
    "from modules.pdf_extraction import get_validated_table_info\n",
    "from modules.pdf_extraction import get_page_pixel_data\n",
    "from modules.pdf_extraction import process_tables_to_df\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import os\n",
    "import pymupdf\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "pdf_path = select_pdf_file()\n",
    "doc = pymupdf.open(pdf_path)\n",
    "total_pages = doc.page_count  # total number of pages in the document\n",
    "page_indices = range(total_pages) # page_indices = range(1562,1567)\n",
    "page_no = 0\n",
    "\n",
    "page = doc.load_page(page_no)\n",
    "extracted_text = page.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extracted_text = extract_text_from_pages(pdf_path, pages=page_no)\n",
    "base64_image = get_page_pixel_data(pdf_path=pdf_path, page_no=page_no, \n",
    "                    dpi = 500, image_type = 'png')\n",
    "\n",
    "num_tables, table_headers, table_location, confidence_score_0 = await get_validated_table_info(\n",
    "    text_input=extracted_text, \n",
    "    open_api_key=open_api_key, \n",
    "    base64_image=base64_image\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pdf_extraction import vision_llm_parser\n",
    "max_retries = 1\n",
    "model = 'gpt-4o'\n",
    "user_text = 'Extract all data from the table(s).'\n",
    "for attempt in range(max_retries):\n",
    "    tasks = []\n",
    "    async with asyncio.TaskGroup() as tg:\n",
    "        for table in table_headers:\n",
    "            tasks.append(tg.create_task(\n",
    "                vision_llm_parser(\n",
    "                    user_text=user_text,\n",
    "                    text_input=extracted_text,\n",
    "                    table_to_target=table,\n",
    "                    base64_image=base64_image,\n",
    "                    open_api_key=open_api_key,\n",
    "                    model= model\n",
    "                )\n",
    "            ))\n",
    "    model_results = [task.result() for task in tasks]\n",
    "    results_output = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Based on the user\\'s request and the provided table header:\\n\\n### Dictionary Output:\\n\\n```python\\n[\\n    {\"0929\": \"HSA 2014WA 08\", \"Size\": \"1.1/2\"},\\n    {\"0929\": \"HSA 2014WA 09\", \"Size\": \"2\"},\\n    {\"0929\": \"HSA 2014WA 10\", \"Size\": \"2.1/2\"},\\n    {\"0929\": \"HSA 2014WA 11\", \"Size\": \"3\"},\\n    {\"0929\": \"HSA 2014WA 12\", \"Size\": \"4\"},\\n    {\"0929\": \"HSA 2014WA 13\", \"Size\": \"5\"},\\n    {\"0929\": \"HSA 2014WA 14\", \"Size\": \"6\"},\\n    {\"0929\": \"HSA 2014WA 16\", \"Size\": \"8\"},\\n    {\"0929\": \"HSA 2014WA 18\", \"Size\": \"10\"},\\n    {\"0929\": \"HSA 2014WA 20\", \"Size\": \"12\"}\\n]\\n```\\n\\nThis output is extracted from the specified table in the top-left position and formatted into a dictionary suitable for conversion to a DataFrame.',\n",
       " 'Sure, here is the extracted data in dictionary format:\\n\\n```python\\n[\\n    {\"0929\": \"HDA 2014WA 08\", \"Size\": \"1.1/2\"},\\n    {\"0929\": \"HDA 2014WA 09\", \"Size\": \"2\"},\\n    {\"0929\": \"HDA 2014WA 10\", \"Size\": \"2.1/2\"},\\n    {\"0929\": \"HDA 2014WA 11\", \"Size\": \"3\"},\\n    {\"0929\": \"HDA 2014WA 12\", \"Size\": \"4\"},\\n    {\"0929\": \"HDA 2014WA 13\", \"Size\": \"5\"},\\n    {\"0929\": \"HDA 2014WA 14\", \"Size\": \"6\"},\\n    {\"0929\": \"HDA 2014WA 16\", \"Size\": \"8\"},\\n    {\"0929\": \"HDA 2014WA 18\", \"Size\": \"10\"},\\n    {\"0929\": \"HDA 2014WA 20\", \"Size\": \"12\"}\\n]\\n```\\n\\nYou can convert this dictionary into a dataframe and export it to Excel as needed.',\n",
       " '```json\\n[\\n  {\\n    \"0929\": \"HSA 2014WB 08\",\\n    \"Size\": \"1.1/2\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 09\",\\n    \"Size\": \"2\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 10\",\\n    \"Size\": \"2.1/2\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 11\",\\n    \"Size\": \"3\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 12\",\\n    \"Size\": \"4\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 13\",\\n    \"Size\": \"5\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 14\",\\n    \"Size\": \"6\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 16\",\\n    \"Size\": \"8\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 18\",\\n    \"Size\": \"10\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WB 20\",\\n    \"Size\": \"12\"\\n  }\\n]\\n```',\n",
       " 'Based on the user\\'s request and the provided text, the data from the table \"Double Acting, Cast Iron Body, NBR Liner, Stainless Steel Disc\" can be extracted as follows:\\n\\n```json\\n[\\n  {\\n    \"0929\": \"HDA 2014WB 08\",\\n    \"Size\": \"1.1/2\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 09\",\\n    \"Size\": \"2\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 10\",\\n    \"Size\": \"2.1/2\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 11\",\\n    \"Size\": \"3\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 12\",\\n    \"Size\": \"4\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 13\",\\n    \"Size\": \"5\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 14\",\\n    \"Size\": \"6\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 16\",\\n    \"Size\": \"8\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 18\",\\n    \"Size\": \"10\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WB 20\",\\n    \"Size\": \"12\"\\n  }\\n]\\n```\\n\\nThis extracted data can be converted to a dataframe and subsequently exported to Excel.',\n",
       " '```json\\n[\\n    {\\n        \"0929\": \"HSA 2014WC 09\",\\n        \"Size\": \"2\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 10\",\\n        \"Size\": \"2.1/2\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 11\",\\n        \"Size\": \"3\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 12\",\\n        \"Size\": \"4\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 13\",\\n        \"Size\": \"5\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 14\",\\n        \"Size\": \"6\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 16\",\\n        \"Size\": \"8\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 18\",\\n        \"Size\": \"10\"\\n    },\\n    {\\n        \"0929\": \"HSA 2014WC 20\",\\n        \"Size\": \"12\"\\n    }\\n]\\n```',\n",
       " 'Based on the provided text document and description, here\\'s the extracted data from the table titled \"Double Acting, Cast Iron Body, EPDM Liner, Ductile Iron Nickel Plated Disc\":\\n\\n```json\\n[\\n  {\\n    \"0929\": \"HDA 2014WC 09\",\\n    \"Size\": \"2\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 10\",\\n    \"Size\": \"2.1/2\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 11\",\\n    \"Size\": \"3\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 12\",\\n    \"Size\": \"4\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 13\",\\n    \"Size\": \"5\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 14\",\\n    \"Size\": \"6\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 16\",\\n    \"Size\": \"8\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 18\",\\n    \"Size\": \"10\"\\n  },\\n  {\\n    \"0929\": \"HDA 2014WC 20\",\\n    \"Size\": \"12\"\\n  }\\n]\\n```',\n",
       " 'Here is the extracted data from the specified table:\\n\\n```json\\n[\\n  {\\n    \"0929\": \"HSA 2014WD 09\",\\n    \"Size\": \"2\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 10\",\\n    \"Size\": \"2.1/2\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 11\",\\n    \"Size\": \"3\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 12\",\\n    \"Size\": \"4\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 13\",\\n    \"Size\": \"5\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 14\",\\n    \"Size\": \"6\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 16\",\\n    \"Size\": \"8\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 18\",\\n    \"Size\": \"10\"\\n  },\\n  {\\n    \"0929\": \"HSA 2014WD 20\",\\n    \"Size\": \"12\"\\n  }\\n]\\n```\\n\\nThis output is designed to be easily converted into a dataframe for further export to Excel.',\n",
       " 'To extract data from the table titled \"Double Acting, Ductile Iron Body, EPDM Liner, Stainless Steel Disc\" located at the bottom far right of the page, here is the dictionary format suitable for conversion to a DataFrame:\\n\\n```python\\n[\\n    {\"0929\": \"HDA 2014WA 08\", \"Size\": \"1.1/2\"},\\n    {\"0929\": \"HDA 2014WA 09\", \"Size\": \"2\"},\\n    {\"0929\": \"HDA 2014WA 10\", \"Size\": \"2.1/2\"},\\n    {\"0929\": \"HDA 2014WA 11\", \"Size\": \"3\"},\\n    {\"0929\": \"HDA 2014WA 12\", \"Size\": \"4\"},\\n    {\"0929\": \"HDA 2014WA 13\", \"Size\": \"5\"},\\n    {\"0929\": \"HDA 2014WA 14\", \"Size\": \"6\"},\\n    {\"0929\": \"HDA 2014WA 16\", \"Size\": \"8\"},\\n    {\"0929\": \"HDA 2014WA 18\", \"Size\": \"10\"},\\n    {\"0929\": \"HDA 2014WA 20\", \"Size\": \"12\"}\\n]\\n```\\n\\nThis data represents the extracted table content with the specific headers and positions indicated. You can convert this list of dictionaries to a DataFrame and export it to Excel as needed.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = []\n",
    "dd = results_output\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pdf_extraction import extract_df_from_string\n",
    "\n",
    "df_list = []\n",
    "max_extract_retries_for_extraction_failures = 1\n",
    "page_number = 7\n",
    "\n",
    "for i, out in enumerate(results_output):\n",
    "    extract_retry_count = 0\n",
    "    max_extract_retries = max_extract_retries_for_extraction_failures  # Maximum number of retries for extraction failures\n",
    "    \n",
    "    while extract_retry_count <= max_extract_retries:\n",
    "            df = extract_df_from_string(out)\n",
    "\n",
    "            # Normalize columns\n",
    "            df.columns = df.columns.astype(str).str.strip().str.strip('\"\\'').str.title()\n",
    "            if table_location[i] == 'Table is present in both the image and the text document':\n",
    "                df[df.columns] = df[df.columns].map(\n",
    "                    lambda val: val if str(val) in extracted_text else \"N/A\"\n",
    "                )\n",
    "                df['table_header_position'] = table_headers[i]\n",
    "            else:\n",
    "                df['table_header_position'] = table_headers[i]\n",
    "                df['page_number'] = page_number + 1\n",
    "\n",
    "            df_list.append(df)\n",
    "            break  # Successfully extracted, exit the retry loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import asyncio\n",
    "async def process_tables_to_df(\n",
    "    table_headers, \n",
    "    table_location, \n",
    "    user_text, \n",
    "    extracted_text, \n",
    "    base64_image, \n",
    "    open_api_key, \n",
    "    page_number,\n",
    "    max_retries=3,\n",
    "    initial_delay=1,\n",
    "    backoff_factor=2,\n",
    "    max_extract_retries_for_extraction_failures=2,\n",
    "    model='gpt-4o'\n",
    "):\n",
    "    \"\"\"\n",
    "    Process tables by calling an LLM parser with exponential backoff.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Processing tables to DataFrame for page {page_number + 1}\")\n",
    "    \n",
    "\n",
    "    # 1) Try first model: 'gpt-4o'\n",
    "    delay = initial_delay\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            logging.debug(f\"[Model {model}] Attempt {attempt+1} of {max_retries}. Delay={delay}\")\n",
    "            tasks = []\n",
    "            async with asyncio.TaskGroup() as tg:\n",
    "                for table in table_headers:\n",
    "                    tasks.append(tg.create_task(\n",
    "                        vision_llm_parser(\n",
    "                            user_text=user_text,\n",
    "                            text_input=extracted_text,\n",
    "                            table_to_target=table,\n",
    "                            base64_image=base64_image,\n",
    "                            open_api_key=open_api_key,\n",
    "                            model= model\n",
    "                        )\n",
    "                    ))\n",
    "            results_output = [task.result() for task in tasks]\n",
    "\n",
    "            logging.info(f\"Successfully retrieved data using model '{model}'.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.warning(\n",
    "                f\"[Model {model}] Attempt {attempt+1} of {max_retries} failed: {e}. \"\n",
    "                f\"Retrying in {delay} second(s)...\"\n",
    "            )\n",
    "            if attempt == max_retries - 1:\n",
    "                logging.warning(f\"Max retries with '{model}' exhausted.\")\n",
    "            else:\n",
    "                await asyncio.sleep(delay)\n",
    "                delay *= backoff_factor\n",
    "\n",
    "    # 2) Process the results into DataFrames\n",
    "    df_list = []\n",
    "    for i, out in enumerate(results_output):\n",
    "        extract_retry_count = 0\n",
    "        max_extract_retries = max_extract_retries_for_extraction_failures  # Maximum number of retries for extraction failures\n",
    "        \n",
    "        while extract_retry_count <= max_extract_retries:\n",
    "\n",
    "                df = extract_df_from_string(out)\n",
    "                logging.debug(f\"Parsed DataFrame for table index {i} with shape {df.shape}\")\n",
    "\n",
    "                # Normalize columns\n",
    "                df.columns = df.columns.astype(str).str.strip().str.strip('\"\\'').str.title()\n",
    "                if table_location[i] == 'Table is present in both the image and the text document':\n",
    "                    df[df.columns] = df[df.columns].map(\n",
    "                        lambda val: val if str(val) in extracted_text else \"N/A\"\n",
    "                    )\n",
    "                    df['table_header_position'] = table_headers[i]\n",
    "                else:\n",
    "                    df['table_header_position'] = table_headers[i]\n",
    "                    df['page_number'] = page_number + 1\n",
    "\n",
    "                df_list.append(df)\n",
    "\n",
    "\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "def extract_table_info(text):\n",
    "    \"\"\"\n",
    "    Extracts table information from a pattern description string.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): Text containing table pattern description\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (num_tables, table_headers)\n",
    "    \"\"\"\n",
    "    logging.debug(\"Extracting table info from text.\")\n",
    "\n",
    "    match_num_tables = re.search(r'Number of Tables on the Page:\\s*(\\d+)', text)\n",
    "    if match_num_tables:\n",
    "        num_tables = int(match_num_tables.group(1))\n",
    "        logging.debug(f\"Found number of tables: {num_tables}\")\n",
    "    else:\n",
    "        num_tables = None\n",
    "        logging.debug(\"No table count found in text.\")\n",
    "\n",
    "    # Modified regex to capture table headers without requiring \"3.\" after\n",
    "    match_headers = re.search(r'Table Headers:\\s*(.*?)(?:\\s*\\n\\s*3\\.|$)', text, re.DOTALL)\n",
    "    if match_headers:\n",
    "        headers_text = match_headers.group(1).strip()\n",
    "        # Remove any extra quotes and whitespace\n",
    "        table_headers = [h.strip().strip('\"') for h in headers_text.split('||')]\n",
    "        logging.debug(f\"Extracted table headers: {table_headers}\")\n",
    "    else:\n",
    "        table_headers = []\n",
    "        logging.debug(\"No table headers found.\")\n",
    "\n",
    "    return num_tables, table_headers\n",
    "\n",
    "out = '1. Number of Tables on the Page: 3 2. Table Headers: \"1 Wire, 40 Metre Coils - Can be found on the top right position of the page\" || \"1 Wire, 100 Metre Coils - Can be found in the middle left position of the page\" || \"Hydraulic Hose, EN853, DIN20022, SAE100R1AT Technical Data - Can be found on the bottom of the page\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " ['1 Wire, 40 Metre Coils - Can be found on the top right position of the page',\n",
       "  '1 Wire, 100 Metre Coils - Can be found in the middle left position of the page',\n",
       "  'Hydraulic Hose, EN853, DIN20022, SAE100R1AT Technical Data - Can be found on the bottom of the page'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_table_info(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No matches found. Returning third run results for table_headers.\n"
     ]
    }
   ],
   "source": [
    "from modules.pdf_extraction import select_pdf_file\n",
    "from modules.pdf_extraction import get_validated_table_info\n",
    "from modules.pdf_extraction import get_page_pixel_data\n",
    "from modules.pdf_extraction import process_tables_to_df\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import os\n",
    "import pymupdf\n",
    "\n",
    "\n",
    "\n",
    "file_name = 'test_7'    \n",
    "user_text='Extract all data from the table(s).'\n",
    "\n",
    "# 1. Load Credientials\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "# Get the API key from the environment variable\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key = open_api_key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Select PDF file and extract text\n",
    "pdf_path = select_pdf_file()\n",
    "doc = pymupdf.open(pdf_path)\n",
    "total_pages = doc.page_count  # total number of pages in the document\n",
    "page_indices = range(total_pages) # page_indices = range(1562,1567)\n",
    "\n",
    "# page_indices can be a list of page numbers to process\n",
    "\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "async def process_page():\n",
    "    tasks = []\n",
    "    results_output_page = []\n",
    "    # Create all tasks first \n",
    "    async with asyncio.TaskGroup() as tg:\n",
    "        for page_no in page_indices:\n",
    "            page = doc.load_page(page_no)\n",
    "            \n",
    "            tabs = page.find_tables()\n",
    "            num_tables_0 = len(tabs.tables)\n",
    "            \n",
    "            # Check for the presence of tables with pymupdf. This will mean images with tables will be ignored. \n",
    "            if num_tables_0 == 0:\n",
    "                print(f\"No tables found on page from pymupdf {page_no + 1}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            extracted_text = page.get_text()\n",
    "            \n",
    "            # extracted_text = extract_text_from_pages(pdf_path, pages=page_no)\n",
    "            base64_image = get_page_pixel_data(pdf_path=pdf_path, page_no=page_no, \n",
    "                                dpi = 500, image_type = 'png')\n",
    "        \n",
    "            num_tables, table_headers, table_location, confidence_score_0 = await get_validated_table_info(\n",
    "                text_input=extracted_text, \n",
    "                open_api_key=open_api_key, \n",
    "                base64_image=base64_image\n",
    "            )\n",
    "\n",
    "            if num_tables == 0:\n",
    "                print(f\"No tables found on page by LLM {page_no + 1}, skipping...\")\n",
    "                continue\n",
    "    \n",
    "            tasks.append(tg.create_task(process_tables_to_df(\n",
    "                table_headers, \n",
    "                table_location,\n",
    "                user_text, \n",
    "                extracted_text, \n",
    "                base64_image, \n",
    "                open_api_key,\n",
    "                page_number=page_no)))\n",
    "            \n",
    "        # Await all tasks to complete\n",
    "        for task in tasks:\n",
    "            results_output_page.append(await task)\n",
    "    \n",
    "    if not results_output_page:\n",
    "        raise ValueError(\"No tables found on any of the processed pages\")\n",
    "            \n",
    "    # df_out_1 = pd.concat(results_output, ignore_index=True)\n",
    "    return results_output_page\n",
    "\n",
    "\n",
    "output_final = await process_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[            0929   Size                              table_header_position  \\\n",
       "  0  HSA 2014WA 08  1.1/2  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  1  HSA 2014WA 09      2  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  2  HSA 2014WA 10  2.1/2  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  3  HSA 2014WA 11      3  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  4  HSA 2014WA 12      4  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  5  HSA 2014WA 13      5  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  6  HSA 2014WA 14      6  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  7  HSA 2014WA 16      8  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  8  HSA 2014WA 18     10  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  9  HSA 2014WA 20     12  - \"Single Acting, Ductile Iron Body, EPDM Line...   \n",
       "  \n",
       "     page_number  \n",
       "  0            1  \n",
       "  1            1  \n",
       "  2            1  \n",
       "  3            1  \n",
       "  4            1  \n",
       "  5            1  \n",
       "  6            1  \n",
       "  7            1  \n",
       "  8            1  \n",
       "  9            1  ,\n",
       "              0929   Size                              table_header_position  \\\n",
       "  0  HDA 2014WA 08  1.1/2  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  1  HDA 2014WA 09      2  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  2  HDA 2014WA 10  2.1/2  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  3  HDA 2014WA 11      3  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  4  HDA 2014WA 12      4  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  5  HDA 2014WA 13      5  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  6  HDA 2014WA 14      6  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  7  HDA 2014WA 16      8  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  8  HDA 2014WA 18     10  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  9  HDA 2014WA 20     12  - \"Double Acting, Ductile Iron Body, EPDM Line...   \n",
       "  \n",
       "     page_number  \n",
       "  0            1  \n",
       "  1            1  \n",
       "  2            1  \n",
       "  3            1  \n",
       "  4            1  \n",
       "  5            1  \n",
       "  6            1  \n",
       "  7            1  \n",
       "  8            1  \n",
       "  9            1  ,\n",
       "              0929   Size                              table_header_position  \\\n",
       "  0  HSA 2014WB 08  1.1/2  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  1  HSA 2014WB 09      2  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  2  HSA 2014WB 10  2.1/2  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  3  HSA 2014WB 11      3  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  4  HSA 2014WB 12      4  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  5  HSA 2014WB 13      5  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  6  HSA 2014WB 14      6  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  7  HSA 2014WB 16      8  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  8  HSA 2014WB 18     10  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  9  HSA 2014WB 20     12  - \"Single Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  \n",
       "     page_number  \n",
       "  0            1  \n",
       "  1            1  \n",
       "  2            1  \n",
       "  3            1  \n",
       "  4            1  \n",
       "  5            1  \n",
       "  6            1  \n",
       "  7            1  \n",
       "  8            1  \n",
       "  9            1  ,\n",
       "              0929   Size                              table_header_position  \\\n",
       "  0  HDA 2014WB 08  1.1/2  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  1  HDA 2014WB 09      2  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  2  HDA 2014WB 10  2.1/2  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  3  HDA 2014WB 11      3  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  4  HDA 2014WB 12      4  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  5  HDA 2014WB 13      5  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  6  HDA 2014WB 14      6  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  7  HDA 2014WB 16      8  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  8  HDA 2014WB 18     10  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  9  HDA 2014WB 20     12  - \"Double Acting, Cast Iron Body, NBR Liner, S...   \n",
       "  \n",
       "     page_number  \n",
       "  0            1  \n",
       "  1            1  \n",
       "  2            1  \n",
       "  3            1  \n",
       "  4            1  \n",
       "  5            1  \n",
       "  6            1  \n",
       "  7            1  \n",
       "  8            1  \n",
       "  9            1  ,\n",
       "              0929   Size                              table_header_position  \\\n",
       "  0  HSA 2014WC 09      2  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  1  HSA 2014WC 10  2.1/2  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  2  HSA 2014WC 11      3  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  3  HSA 2014WC 12      4  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  4  HSA 2014WC 13      5  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  5  HSA 2014WC 14      6  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  6  HSA 2014WC 16      8  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  7  HSA 2014WC 18     10  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  8  HSA 2014WC 20     12  - \"Single Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  \n",
       "     page_number  \n",
       "  0            1  \n",
       "  1            1  \n",
       "  2            1  \n",
       "  3            1  \n",
       "  4            1  \n",
       "  5            1  \n",
       "  6            1  \n",
       "  7            1  \n",
       "  8            1  ,\n",
       "              0929   Size                              table_header_position  \\\n",
       "  0  HDA 2014WC 09      2  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  1  HDA 2014WC 10  2.1/2  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  2  HDA 2014WC 11      3  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  3  HDA 2014WC 12      4  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  4  HDA 2014WC 13      5  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  5  HDA 2014WC 14      6  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  6  HDA 2014WC 16      8  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  7  HDA 2014WC 18     10  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  8  HDA 2014WC 20     12  - \"Double Acting, Cast Iron Body, EPDM Liner, ...   \n",
       "  \n",
       "     page_number  \n",
       "  0            1  \n",
       "  1            1  \n",
       "  2            1  \n",
       "  3            1  \n",
       "  4            1  \n",
       "  5            1  \n",
       "  6            1  \n",
       "  7            1  \n",
       "  8            1  ]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 21:28:25,297 - INFO - Writing output to Excel at 'files/Tester_2.xlsx' with option=1.\n",
      "2025-03-01 21:28:25,373 - INFO - Excel file writing complete.\n"
     ]
    }
   ],
   "source": [
    "from modules.pdf_extraction import write_output_final\n",
    "write_output_final(output_final, excel_path='files/Tester_2.xlsx', option=1, gap_rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymupdf\n",
    "\n",
    "from modules.pdf_extraction import select_pdf_file\n",
    "\n",
    "pdf_path = select_pdf_file()\n",
    "\n",
    "# Open some document, for example a PDF (could also be EPUB, XPS, etc.)\n",
    "doc = pymupdf.open(pdf_path)\n",
    "\n",
    "# Load a desired page. This works via 0-based numbers\n",
    "page = doc[0]  # this is the first page\n",
    "\n",
    "# Look for tables on this page and display the table count\n",
    "tabs = page.find_tables()\n",
    "num_tables = len(tabs.tables)\n",
    "num_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "\n",
    "# from modules.pdf_extraction import select_pdf_file\n",
    "# from modules.pdf_extraction import extract_text_from_pages\n",
    "\n",
    "# pdf_path = select_pdf_file()\n",
    "\n",
    "# def split_pdf(input_path, output_path_1, output_path_2, split_page):\n",
    "#     \"\"\"\n",
    "#     Split a PDF file into two separate PDF files.\n",
    "    \n",
    "#     Args:\n",
    "#         input_path (str): Path to the input PDF file\n",
    "#         output_path_1 (str): Path where to save the first part\n",
    "#         output_path_2 (str): Path where to save the second part\n",
    "#         split_page (int): The page number where to split (this page will be the first page of the second PDF)\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Create PDF reader object\n",
    "#         reader = PdfReader(input_path)\n",
    "        \n",
    "#         # Get total number of pages\n",
    "#         total_pages = len(reader.pages)\n",
    "        \n",
    "#         if split_page >= total_pages:\n",
    "#             raise ValueError(\"Split page number cannot be greater than total pages\")\n",
    "        \n",
    "#         # Create two PDF writer objects\n",
    "#         writer1 = PdfWriter()\n",
    "#         writer2 = PdfWriter()\n",
    "        \n",
    "#         # Add pages to first output PDF (before split point)\n",
    "#         for page in range(split_page):\n",
    "#             writer1.add_page(reader.pages[page])\n",
    "            \n",
    "#         # Add pages to second output PDF (from split point to end)\n",
    "#         for page in range(split_page, total_pages):\n",
    "#             writer2.add_page(reader.pages[page])\n",
    "            \n",
    "#         # Save the first part\n",
    "#         with open(output_path_1, 'wb') as output1:\n",
    "#             writer1.write(output1)\n",
    "            \n",
    "#         # Save the second part\n",
    "#         with open(output_path_2, 'wb') as output2:\n",
    "#             writer2.write(output2)\n",
    "            \n",
    "#         return True\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {str(e)}\")\n",
    "#         return False\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     input_file = pdf_path  # Replace with your PDF file\n",
    "#     output_file1 = \"part1.pdf\"\n",
    "#     output_file2 = \"part2.pdf\"\n",
    "#     split_at_page = 1000   # Split after first page (0-based index)\n",
    "    \n",
    "#     if os.path.exists(input_file):\n",
    "#         success = split_pdf(input_file, output_file1, output_file2, split_at_page)\n",
    "#         if success:\n",
    "#             print(f\"PDF split successfully!\")\n",
    "#             print(f\"First part saved as: {output_file1}\")\n",
    "#             print(f\"Second part saved as: {output_file2}\")\n",
    "#         else:\n",
    "#             print(\"Failed to split PDF.\")\n",
    "#     else:\n",
    "#         print(f\"Input file '{input_file}' not found.\")\n",
    "        \n",
    "# main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
